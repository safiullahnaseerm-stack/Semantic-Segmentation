{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "#  Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#  Restore Model Code\n",
        "if not os.path.exists('/content/models'):\n",
        "    print(\"Restoring Code...\")\n",
        "    !git clone https://github.com/Gabrysse/MLDL2024_project1.git temp_repo\n",
        "    shutil.copytree('temp_repo/models', '/content/models')\n",
        "    shutil.rmtree('temp_repo')\n",
        "\n",
        "#  Add models to system path\n",
        "sys.path.append('/content/models')\n",
        "\n",
        "#  Restore Dataset (GTA5 + Cityscapes)\n",
        "if not os.path.exists('/content/dataset/project_data/gta5'):\n",
        "    print(\"Restoring Dataset...\")\n",
        "    zip_path_1 = '/content/drive/MyDrive/semseg/project_data.zip'\n",
        "    zip_path_2 = '/content/drive/MyDrive/project_data.zip'\n",
        "\n",
        "    if os.path.exists(zip_path_1):\n",
        "        shutil.unpack_archive(zip_path_1, '/content/dataset')\n",
        "        print(\"Dataset extracted.\")\n",
        "    elif os.path.exists(zip_path_2):\n",
        "        shutil.unpack_archive(zip_path_2, '/content/dataset')\n",
        "        print(\"Dataset extracted.\")\n",
        "    else:\n",
        "        print(\"Error: project_data.zip not found.\")"
      ],
      "metadata": {
        "id": "BWK2z2l0B9M0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d451ce2-5de5-4f55-c04f-201a570bf67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "CHECKPOINT_NAME = 'bisenet_extension_final.pth'\n",
        "# Pointing to your BEST model (Thresholded - 24.83%)\n",
        "PRETRAINED_PATH = '/content/drive/MyDrive/semseg/bisenet_dacs_thresholded.pth'\n",
        "SAVE_PATH = f'/content/drive/MyDrive/semseg/{CHECKPOINT_NAME}'\n",
        "\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 4\n",
        "LR = 1e-3    # Low LR for fine-tuning\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "GTA_PATH = '/content/dataset/project_data/gta5'\n",
        "CITYSCAPES_PATH = '/content/dataset/project_data/cityscapes'\n",
        "\n",
        "# --- IMPORTS ---\n",
        "if os.path.exists('/content/MLDL2024_project1'):\n",
        "    sys.path.append('/content/MLDL2024_project1')\n",
        "try:\n",
        "    from models.bisenet.build_bisenet import BiSeNet\n",
        "except ImportError:\n",
        "    print(\"Error: BiSeNet not found.\")\n",
        "\n",
        "# --- 1. DICE LOSS IMPLEMENTATION ---\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, num_classes=19, smooth=1.0, ignore_index=255):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.smooth = smooth\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        target_one_hot = F.one_hot(target.clamp(0, self.num_classes-1), num_classes=self.num_classes)\n",
        "        target_one_hot = target_one_hot.permute(0, 3, 1, 2).float()\n",
        "\n",
        "        mask = (target != self.ignore_index).unsqueeze(1).float()\n",
        "        pred = pred * mask\n",
        "        target_one_hot = target_one_hot * mask\n",
        "\n",
        "        intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
        "        union = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
        "\n",
        "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
        "        return 1.0 - dice.mean()\n",
        "\n",
        "# --- 2. DATASET ---\n",
        "class GTA5_City_Dataset(Dataset):\n",
        "    def __init__(self, gta_root, city_root):\n",
        "        self.gta_images_dir = os.path.join(gta_root, 'images')\n",
        "        self.gta_masks_dir = os.path.join(gta_root, 'labels')\n",
        "        self.gta_images = sorted(os.listdir(self.gta_images_dir))\n",
        "        self.city_images_dir = os.path.join(city_root, 'leftImg8bit', 'train')\n",
        "        self.city_images = []\n",
        "        if os.path.exists(self.city_images_dir):\n",
        "            for city in os.listdir(self.city_images_dir):\n",
        "                c_path = os.path.join(self.city_images_dir, city)\n",
        "                if os.path.isdir(c_path):\n",
        "                    for f in os.listdir(c_path):\n",
        "                        if f.endswith('_leftImg8bit.png'):\n",
        "                            self.city_images.append(os.path.join(c_path, f))\n",
        "\n",
        "        self.normalize = transforms.Compose([\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        self.id_mapping = {\n",
        "            7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 17: 5,\n",
        "            19: 6, 20: 7, 21: 8, 22: 9, 23: 10, 24: 11, 25: 12,\n",
        "            26: 13, 27: 14, 28: 15, 31: 16, 32: 17, 33: 18\n",
        "        }\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self): return len(self.gta_images)\n",
        "    def __getitem__(self, idx):\n",
        "        gta_path = os.path.join(self.gta_images_dir, self.gta_images[idx])\n",
        "        mask_path = os.path.join(self.gta_masks_dir, self.gta_images[idx])\n",
        "        gta_img = Image.open(gta_path).convert('RGB').resize((1280, 720), Image.BILINEAR)\n",
        "        gta_mask = Image.open(mask_path).resize((1280, 720), Image.NEAREST)\n",
        "\n",
        "        rand_idx = random.randint(0, len(self.city_images) - 1)\n",
        "        city_img = Image.open(self.city_images[rand_idx]).convert('RGB').resize((1280, 720), Image.BILINEAR)\n",
        "\n",
        "        gta_t = self.normalize(self.to_tensor(gta_img))\n",
        "        city_t = self.normalize(self.to_tensor(city_img))\n",
        "\n",
        "        mask_np = np.array(gta_mask)\n",
        "        gta_lbl = np.full(mask_np.shape, 255, dtype=np.uint8)\n",
        "        for k, v in self.id_mapping.items(): gta_lbl[mask_np == k] = v\n",
        "\n",
        "        return gta_t, torch.from_numpy(gta_lbl).long(), city_t\n",
        "\n",
        "# --- 3. TRAINING LOOP ---\n",
        "print(\"Starting Step 5 Extension: Hybrid Loss Fine-Tuning...\")\n",
        "\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18').to(DEVICE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# THE EXTENSION: Using two losses together\n",
        "ce_criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "dice_criterion = DiceLoss(num_classes=19, ignore_index=255)\n",
        "\n",
        "if os.path.exists(PRETRAINED_PATH):\n",
        "    print(f\"Loading Best Model: {PRETRAINED_PATH}\")\n",
        "    checkpoint = torch.load(PRETRAINED_PATH, map_location=DEVICE)\n",
        "\n",
        "    # Robust Loading logic\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        print(\"Model loaded (state_dict).\")\n",
        "    elif isinstance(checkpoint, dict) and 'student' in checkpoint:\n",
        "         model.load_state_dict(checkpoint['student'])\n",
        "         print(\"Model loaded (student key).\")\n",
        "    else:\n",
        "        model.load_state_dict(checkpoint)\n",
        "        print(\"Model loaded (direct).\")\n",
        "else:\n",
        "    print(\"Error: Best model not found. Cannot fine-tune.\")\n",
        "    sys.exit()\n",
        "\n",
        "dataset = GTA5_City_Dataset(GTA_PATH, CITYSCAPES_PATH)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "model.train()\n",
        "print(f\"Training for {EPOCHS} epochs...\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for i, (gta_img, gta_lbl, city_img) in enumerate(loader):\n",
        "        gta_img, gta_lbl, city_img = gta_img.to(DEVICE), gta_lbl.to(DEVICE), city_img.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 1. Pseudo-Labeling (Student Self-Training)\n",
        "        with torch.no_grad():\n",
        "            city_out = model(city_img)\n",
        "            if isinstance(city_out, tuple): city_out = city_out[0]\n",
        "            city_pseudo_lbl = torch.argmax(city_out, dim=1)\n",
        "\n",
        "        # 2. Mix (ClassMix)\n",
        "        batch_size = gta_img.shape[0]\n",
        "        mixed_img = city_img.clone()\n",
        "        mixed_lbl = city_pseudo_lbl.clone()\n",
        "        for b in range(batch_size):\n",
        "            classes = torch.unique(gta_lbl[b])\n",
        "            classes = classes[classes != 255]\n",
        "            if len(classes) > 0:\n",
        "                perm = torch.randperm(len(classes))\n",
        "                sel = classes[perm[:(len(classes)+1)//2]]\n",
        "                mask = torch.zeros_like(gta_lbl[b]).bool()\n",
        "                for c in sel: mask = mask | (gta_lbl[b] == c)\n",
        "                mixed_img[b, :, mask] = gta_img[b, :, mask]\n",
        "                mixed_lbl[b, mask] = gta_lbl[b, mask]\n",
        "\n",
        "        # 3. Forward\n",
        "        out = model(mixed_img)\n",
        "\n",
        "        # 4. HYBRID LOSS CALCULATION\n",
        "        loss_ce = ce_criterion(out[0], mixed_lbl)\n",
        "        loss_dice = dice_criterion(out[0], mixed_lbl)\n",
        "\n",
        "        # Weighted combination\n",
        "        total_loss = loss_ce + loss_dice\n",
        "        total_loss += 0.1 * ce_criterion(out[1], mixed_lbl) + 0.1 * ce_criterion(out[2], mixed_lbl)\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Ep {epoch+1} | It {i} | Loss: {total_loss.item():.4f}\")\n",
        "\n",
        "    torch.save({'model_state_dict': model.state_dict(), 'epoch': epoch}, SAVE_PATH)\n",
        "    print(f\"Epoch {epoch+1} Saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqLgUzLAp5tD",
        "outputId": "a85b8baa-9b78-4549-bdef-bda8a7ed461f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Step 5 Extension: Hybrid Loss Fine-Tuning...\n",
            "Loading Best Model: /content/drive/MyDrive/semseg/bisenet_dacs_thresholded.pth\n",
            "Model loaded (state_dict).\n",
            "Training for 15 epochs...\n",
            "Ep 1 | It 0 | Loss: 1.1188\n",
            "Ep 1 | It 50 | Loss: 1.1375\n",
            "Ep 1 | It 100 | Loss: 1.4799\n",
            "Ep 1 | It 150 | Loss: 1.0322\n",
            "Ep 1 | It 200 | Loss: 1.0758\n",
            "Ep 1 | It 250 | Loss: 1.1858\n",
            "Ep 1 | It 300 | Loss: 1.0374\n",
            "Ep 1 | It 350 | Loss: 1.1032\n",
            "Ep 1 | It 400 | Loss: 0.9482\n",
            "Ep 1 | It 450 | Loss: 1.0889\n",
            "Ep 1 | It 500 | Loss: 1.1200\n",
            "Ep 1 | It 550 | Loss: 0.9256\n",
            "Ep 1 | It 600 | Loss: 0.9499\n",
            "Epoch 1 Saved.\n",
            "Ep 2 | It 0 | Loss: 0.9258\n",
            "Ep 2 | It 50 | Loss: 0.9396\n",
            "Ep 2 | It 100 | Loss: 0.9202\n",
            "Ep 2 | It 150 | Loss: 0.9819\n",
            "Ep 2 | It 200 | Loss: 1.0533\n",
            "Ep 2 | It 250 | Loss: 0.8760\n",
            "Ep 2 | It 300 | Loss: 0.9970\n",
            "Ep 2 | It 350 | Loss: 0.9672\n",
            "Ep 2 | It 400 | Loss: 0.9664\n",
            "Ep 2 | It 450 | Loss: 0.9077\n",
            "Ep 2 | It 500 | Loss: 0.9104\n",
            "Ep 2 | It 550 | Loss: 1.0650\n",
            "Ep 2 | It 600 | Loss: 1.0156\n",
            "Epoch 2 Saved.\n",
            "Ep 3 | It 0 | Loss: 0.9137\n",
            "Ep 3 | It 50 | Loss: 0.8652\n",
            "Ep 3 | It 100 | Loss: 1.0118\n",
            "Ep 3 | It 150 | Loss: 0.8916\n",
            "Ep 3 | It 200 | Loss: 0.8921\n",
            "Ep 3 | It 250 | Loss: 0.7713\n",
            "Ep 3 | It 300 | Loss: 0.7469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "CHECKPOINT_NAME = 'bisenet_extension_final.pth'\n",
        "# Your baseline best model\n",
        "PRETRAINED_PATH = '/content/drive/MyDrive/semseg/bisenet_dacs_thresholded.pth'\n",
        "# Where the new training is saved\n",
        "SAVE_PATH = f'/content/drive/MyDrive/semseg/{CHECKPOINT_NAME}'\n",
        "\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 4       # OOM Safe\n",
        "ACCUM_STEPS = 2      # Gradient Accumulation\n",
        "LR = 1e-3\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "GTA_PATH = '/content/dataset/project_data/gta5'\n",
        "CITYSCAPES_PATH = '/content/dataset/project_data/cityscapes'\n",
        "\n",
        "# --- IMPORTS ---\n",
        "if os.path.exists('/content/MLDL2024_project1'):\n",
        "    sys.path.append('/content/MLDL2024_project1')\n",
        "try:\n",
        "    from models.bisenet.build_bisenet import BiSeNet\n",
        "except ImportError:\n",
        "    print(\"Error: BiSeNet not found.\")\n",
        "\n",
        "# --- DICE LOSS ---\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, num_classes=19, smooth=1.0, ignore_index=255):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.smooth = smooth\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        target_one_hot = F.one_hot(target.clamp(0, self.num_classes-1), num_classes=self.num_classes)\n",
        "        target_one_hot = target_one_hot.permute(0, 3, 1, 2).float()\n",
        "\n",
        "        mask = (target != self.ignore_index).unsqueeze(1).float()\n",
        "        pred = pred * mask\n",
        "        target_one_hot = target_one_hot * mask\n",
        "\n",
        "        intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
        "        union = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
        "\n",
        "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
        "        return 1.0 - dice.mean()\n",
        "\n",
        "# --- DATASET ---\n",
        "class GTA5_City_Dataset(Dataset):\n",
        "    def __init__(self, gta_root, city_root):\n",
        "        self.gta_images_dir = os.path.join(gta_root, 'images')\n",
        "        self.gta_masks_dir = os.path.join(gta_root, 'labels')\n",
        "        self.gta_images = sorted(os.listdir(self.gta_images_dir))\n",
        "        self.city_images_dir = os.path.join(city_root, 'leftImg8bit', 'train')\n",
        "        self.city_images = []\n",
        "        if os.path.exists(self.city_images_dir):\n",
        "            for city in os.listdir(self.city_images_dir):\n",
        "                c_path = os.path.join(self.city_images_dir, city)\n",
        "                if os.path.isdir(c_path):\n",
        "                    for f in os.listdir(c_path):\n",
        "                        if f.endswith('_leftImg8bit.png'):\n",
        "                            self.city_images.append(os.path.join(c_path, f))\n",
        "\n",
        "        self.normalize = transforms.Compose([\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        self.id_mapping = {\n",
        "            7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 17: 5,\n",
        "            19: 6, 20: 7, 21: 8, 22: 9, 23: 10, 24: 11, 25: 12,\n",
        "            26: 13, 27: 14, 28: 15, 31: 16, 32: 17, 33: 18\n",
        "        }\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self): return len(self.gta_images)\n",
        "    def __getitem__(self, idx):\n",
        "        gta_path = os.path.join(self.gta_images_dir, self.gta_images[idx])\n",
        "        mask_path = os.path.join(self.gta_masks_dir, self.gta_images[idx])\n",
        "        gta_img = Image.open(gta_path).convert('RGB').resize((1280, 720), Image.BILINEAR)\n",
        "        gta_mask = Image.open(mask_path).resize((1280, 720), Image.NEAREST)\n",
        "\n",
        "        rand_idx = random.randint(0, len(self.city_images) - 1)\n",
        "        city_img = Image.open(self.city_images[rand_idx]).convert('RGB').resize((1280, 720), Image.BILINEAR)\n",
        "\n",
        "        gta_t = self.normalize(self.to_tensor(gta_img))\n",
        "        city_t = self.normalize(self.to_tensor(city_img))\n",
        "\n",
        "        mask_np = np.array(gta_mask)\n",
        "        gta_lbl = np.full(mask_np.shape, 255, dtype=np.uint8)\n",
        "        for k, v in self.id_mapping.items(): gta_lbl[mask_np == k] = v\n",
        "\n",
        "        return gta_t, torch.from_numpy(gta_lbl).long(), city_t\n",
        "\n",
        "# --- TRAINING LOOP ---\n",
        "print(\"Starting Step 5 Extension: Hybrid Loss (Resumable)...\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18').to(DEVICE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "ce_criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "dice_criterion = DiceLoss(num_classes=19, ignore_index=255)\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "# --- SMART RESUME LOGIC ---\n",
        "if os.path.exists(SAVE_PATH):\n",
        "    print(f\"Found interrupted training: {SAVE_PATH}\")\n",
        "    print(\"Resuming from latest epoch...\")\n",
        "    checkpoint = torch.load(SAVE_PATH, map_location=DEVICE)\n",
        "\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        start_epoch = checkpoint.get('epoch', 0) + 1\n",
        "    else:\n",
        "        # Fallback if weird format\n",
        "        model.load_state_dict(checkpoint)\n",
        "\n",
        "elif os.path.exists(PRETRAINED_PATH):\n",
        "    print(f\"Starting Fresh Extension from Best Model: {PRETRAINED_PATH}\")\n",
        "    checkpoint = torch.load(PRETRAINED_PATH, map_location=DEVICE)\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    elif isinstance(checkpoint, dict) and 'student' in checkpoint:\n",
        "         model.load_state_dict(checkpoint['student'])\n",
        "    else:\n",
        "        model.load_state_dict(checkpoint)\n",
        "else:\n",
        "    print(\"Error: No checkpoint found.\")\n",
        "    sys.exit()\n",
        "\n",
        "dataset = GTA5_City_Dataset(GTA_PATH, CITYSCAPES_PATH)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "\n",
        "print(f\"Training from Epoch {start_epoch} to {EPOCHS}...\")\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    for i, (gta_img, gta_lbl, city_img) in enumerate(loader):\n",
        "        gta_img, gta_lbl, city_img = gta_img.to(DEVICE), gta_lbl.to(DEVICE), city_img.to(DEVICE)\n",
        "\n",
        "        # 1. Pseudo-Labeling\n",
        "        with torch.no_grad():\n",
        "            city_out = model(city_img)\n",
        "            if isinstance(city_out, tuple): city_out = city_out[0]\n",
        "            city_pseudo_lbl = torch.argmax(city_out, dim=1)\n",
        "\n",
        "        # 2. Mix\n",
        "        batch_size = gta_img.shape[0]\n",
        "        mixed_img = city_img.clone()\n",
        "        mixed_lbl = city_pseudo_lbl.clone()\n",
        "        for b in range(batch_size):\n",
        "            classes = torch.unique(gta_lbl[b])\n",
        "            classes = classes[classes != 255]\n",
        "            if len(classes) > 0:\n",
        "                perm = torch.randperm(len(classes))\n",
        "                sel = classes[perm[:(len(classes)+1)//2]]\n",
        "                mask = torch.zeros_like(gta_lbl[b]).bool()\n",
        "                for c in sel: mask = mask | (gta_lbl[b] == c)\n",
        "                mixed_img[b, :, mask] = gta_img[b, :, mask]\n",
        "                mixed_lbl[b, mask] = gta_lbl[b, mask]\n",
        "\n",
        "        # 3. Forward\n",
        "        out = model(mixed_img)\n",
        "\n",
        "        # 4. Hybrid Loss\n",
        "        loss_ce = ce_criterion(out[0], mixed_lbl)\n",
        "        loss_dice = dice_criterion(out[0], mixed_lbl)\n",
        "\n",
        "        total_loss = loss_ce + loss_dice\n",
        "        total_loss += 0.1 * ce_criterion(out[1], mixed_lbl) + 0.1 * ce_criterion(out[2], mixed_lbl)\n",
        "\n",
        "        # Gradient Accumulation\n",
        "        total_loss = total_loss / ACCUM_STEPS\n",
        "        total_loss.backward()\n",
        "\n",
        "        if (i + 1) % ACCUM_STEPS == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Ep {epoch+1} | It {i} | Loss: {total_loss.item() * ACCUM_STEPS:.4f}\")\n",
        "\n",
        "    # Save at end of epoch\n",
        "    torch.save({'model_state_dict': model.state_dict(), 'epoch': epoch}, SAVE_PATH)\n",
        "    print(f\"Epoch {epoch+1} Saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnR27MI1z_69",
        "outputId": "7590cc08-ff83-4839-9381-c2627b7fa970"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Step 5 Extension: Hybrid Loss (Resumable)...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 200MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 171M/171M [00:01<00:00, 127MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found interrupted training: /content/drive/MyDrive/semseg/bisenet_extension_final.pth\n",
            "Resuming from latest epoch...\n",
            "Training from Epoch 2 to 15...\n",
            "Ep 3 | It 0 | Loss: 0.9271\n",
            "Ep 3 | It 100 | Loss: 0.9619\n",
            "Ep 3 | It 200 | Loss: 0.8656\n",
            "Ep 3 | It 300 | Loss: 0.8507\n",
            "Ep 3 | It 400 | Loss: 0.8059\n",
            "Ep 3 | It 500 | Loss: 0.8762\n",
            "Ep 3 | It 600 | Loss: 0.9383\n",
            "Epoch 3 Saved.\n",
            "Ep 4 | It 0 | Loss: 0.8067\n",
            "Ep 4 | It 100 | Loss: 0.7464\n",
            "Ep 4 | It 200 | Loss: 0.9241\n",
            "Ep 4 | It 300 | Loss: 0.7136\n",
            "Ep 4 | It 400 | Loss: 0.7868\n",
            "Ep 4 | It 500 | Loss: 0.7510\n",
            "Ep 4 | It 600 | Loss: 0.6972\n",
            "Epoch 4 Saved.\n",
            "Ep 5 | It 0 | Loss: 0.7886\n",
            "Ep 5 | It 100 | Loss: 0.7279\n",
            "Ep 5 | It 200 | Loss: 0.7354\n",
            "Ep 5 | It 300 | Loss: 0.8419\n",
            "Ep 5 | It 400 | Loss: 0.7557\n",
            "Ep 5 | It 500 | Loss: 0.6576\n",
            "Ep 5 | It 600 | Loss: 0.7696\n",
            "Epoch 5 Saved.\n",
            "Ep 6 | It 0 | Loss: 0.7435\n",
            "Ep 6 | It 100 | Loss: 0.5725\n",
            "Ep 6 | It 200 | Loss: 0.7646\n",
            "Ep 6 | It 300 | Loss: 0.7464\n",
            "Ep 6 | It 400 | Loss: 0.6309\n",
            "Ep 6 | It 500 | Loss: 0.9299\n",
            "Ep 6 | It 600 | Loss: 0.7633\n",
            "Epoch 6 Saved.\n",
            "Ep 7 | It 0 | Loss: 0.6510\n",
            "Ep 7 | It 100 | Loss: 0.7420\n",
            "Ep 7 | It 200 | Loss: 0.7275\n",
            "Ep 7 | It 300 | Loss: 0.6832\n",
            "Ep 7 | It 400 | Loss: 0.6916\n",
            "Ep 7 | It 500 | Loss: 0.7425\n",
            "Ep 7 | It 600 | Loss: 0.6206\n",
            "Epoch 7 Saved.\n",
            "Ep 8 | It 0 | Loss: 0.6318\n",
            "Ep 8 | It 100 | Loss: 0.7174\n",
            "Ep 8 | It 200 | Loss: 0.5823\n",
            "Ep 8 | It 300 | Loss: 0.6279\n",
            "Ep 8 | It 400 | Loss: 0.6745\n",
            "Ep 8 | It 500 | Loss: 0.5373\n",
            "Ep 8 | It 600 | Loss: 0.7446\n",
            "Epoch 8 Saved.\n",
            "Ep 9 | It 0 | Loss: 0.6013\n",
            "Ep 9 | It 100 | Loss: 0.7313\n",
            "Ep 9 | It 200 | Loss: 0.6053\n",
            "Ep 9 | It 300 | Loss: 0.7593\n",
            "Ep 9 | It 400 | Loss: 0.8103\n",
            "Ep 9 | It 500 | Loss: 0.7346\n",
            "Ep 9 | It 600 | Loss: 0.9099\n",
            "Epoch 9 Saved.\n",
            "Ep 10 | It 0 | Loss: 0.6508\n",
            "Ep 10 | It 100 | Loss: 0.6579\n",
            "Ep 10 | It 200 | Loss: 0.6179\n",
            "Ep 10 | It 300 | Loss: 0.7245\n",
            "Ep 10 | It 400 | Loss: 0.6386\n",
            "Ep 10 | It 500 | Loss: 0.6957\n",
            "Ep 10 | It 600 | Loss: 0.7905\n",
            "Epoch 10 Saved.\n",
            "Ep 11 | It 0 | Loss: 0.6254\n",
            "Ep 11 | It 100 | Loss: 0.6594\n",
            "Ep 11 | It 200 | Loss: 0.6915\n",
            "Ep 11 | It 300 | Loss: 0.8126\n",
            "Ep 11 | It 400 | Loss: 0.6685\n",
            "Ep 11 | It 500 | Loss: 0.6515\n",
            "Ep 11 | It 600 | Loss: 0.6066\n",
            "Epoch 11 Saved.\n",
            "Ep 12 | It 0 | Loss: 0.6833\n",
            "Ep 12 | It 100 | Loss: 0.7635\n",
            "Ep 12 | It 200 | Loss: 0.6581\n",
            "Ep 12 | It 300 | Loss: 0.6732\n",
            "Ep 12 | It 400 | Loss: 0.6061\n",
            "Ep 12 | It 500 | Loss: 0.6984\n",
            "Ep 12 | It 600 | Loss: 0.7420\n",
            "Epoch 12 Saved.\n",
            "Ep 13 | It 0 | Loss: 0.6263\n",
            "Ep 13 | It 100 | Loss: 0.5777\n",
            "Ep 13 | It 200 | Loss: 0.6816\n",
            "Ep 13 | It 300 | Loss: 0.6147\n",
            "Ep 13 | It 400 | Loss: 0.5613\n",
            "Ep 13 | It 500 | Loss: 0.6527\n",
            "Ep 13 | It 600 | Loss: 0.7271\n",
            "Epoch 13 Saved.\n",
            "Ep 14 | It 0 | Loss: 0.6811\n",
            "Ep 14 | It 100 | Loss: 0.5951\n",
            "Ep 14 | It 200 | Loss: 0.5836\n",
            "Ep 14 | It 300 | Loss: 0.7098\n",
            "Ep 14 | It 400 | Loss: 0.7965\n",
            "Ep 14 | It 500 | Loss: 0.6264\n",
            "Ep 14 | It 600 | Loss: 0.6277\n",
            "Epoch 14 Saved.\n",
            "Ep 15 | It 0 | Loss: 0.6353\n",
            "Ep 15 | It 100 | Loss: 0.6889\n",
            "Ep 15 | It 200 | Loss: 0.6501\n",
            "Ep 15 | It 300 | Loss: 0.6325\n",
            "Ep 15 | It 400 | Loss: 0.7559\n",
            "Ep 15 | It 500 | Loss: 0.5825\n",
            "Ep 15 | It 600 | Loss: 0.6089\n",
            "Epoch 15 Saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# SAVE AS A NEW FILE so we don't overwrite the 26.68% model if this gets worse\n",
        "SAVE_NAME = 'bisenet_extension_30ep.pth'\n",
        "# Load the model you just finished (26.68%)\n",
        "PRETRAINED_PATH = '/content/drive/MyDrive/semseg/bisenet_extension_final.pth'\n",
        "SAVE_PATH = f'/content/drive/MyDrive/semseg/{SAVE_NAME}'\n",
        "\n",
        "TOTAL_EPOCHS = 30    # We are going from Epoch 15 -> 30\n",
        "BATCH_SIZE = 4       # Keep OOM Safe settings\n",
        "ACCUM_STEPS = 2\n",
        "LR = 1e-3\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "GTA_PATH = '/content/dataset/project_data/gta5'\n",
        "CITYSCAPES_PATH = '/content/dataset/project_data/cityscapes'\n",
        "\n",
        "# --- IMPORTS ---\n",
        "if os.path.exists('/content/MLDL2024_project1'):\n",
        "    sys.path.append('/content/MLDL2024_project1')\n",
        "try:\n",
        "    from models.bisenet.build_bisenet import BiSeNet\n",
        "except ImportError:\n",
        "    print(\"Error: BiSeNet not found.\")\n",
        "\n",
        "# --- DICE LOSS ---\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, num_classes=19, smooth=1.0, ignore_index=255):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.smooth = smooth\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        target_one_hot = F.one_hot(target.clamp(0, self.num_classes-1), num_classes=self.num_classes)\n",
        "        target_one_hot = target_one_hot.permute(0, 3, 1, 2).float()\n",
        "\n",
        "        mask = (target != self.ignore_index).unsqueeze(1).float()\n",
        "        pred = pred * mask\n",
        "        target_one_hot = target_one_hot * mask\n",
        "\n",
        "        intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
        "        union = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
        "\n",
        "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
        "        return 1.0 - dice.mean()\n",
        "\n",
        "# --- DATASET ---\n",
        "class GTA5_City_Dataset(Dataset):\n",
        "    def __init__(self, gta_root, city_root):\n",
        "        self.gta_images_dir = os.path.join(gta_root, 'images')\n",
        "        self.gta_masks_dir = os.path.join(gta_root, 'labels')\n",
        "        self.gta_images = sorted(os.listdir(self.gta_images_dir))\n",
        "        self.city_images_dir = os.path.join(city_root, 'leftImg8bit', 'train')\n",
        "        self.city_images = []\n",
        "        if os.path.exists(self.city_images_dir):\n",
        "            for city in os.listdir(self.city_images_dir):\n",
        "                c_path = os.path.join(self.city_images_dir, city)\n",
        "                if os.path.isdir(c_path):\n",
        "                    for f in os.listdir(c_path):\n",
        "                        if f.endswith('_leftImg8bit.png'):\n",
        "                            self.city_images.append(os.path.join(c_path, f))\n",
        "\n",
        "        self.normalize = transforms.Compose([\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        self.id_mapping = {\n",
        "            7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 17: 5,\n",
        "            19: 6, 20: 7, 21: 8, 22: 9, 23: 10, 24: 11, 25: 12,\n",
        "            26: 13, 27: 14, 28: 15, 31: 16, 32: 17, 33: 18\n",
        "        }\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self): return len(self.gta_images)\n",
        "    def __getitem__(self, idx):\n",
        "        gta_path = os.path.join(self.gta_images_dir, self.gta_images[idx])\n",
        "        mask_path = os.path.join(self.gta_masks_dir, self.gta_images[idx])\n",
        "        gta_img = Image.open(gta_path).convert('RGB').resize((1280, 720), Image.BILINEAR)\n",
        "        gta_mask = Image.open(mask_path).resize((1280, 720), Image.NEAREST)\n",
        "\n",
        "        rand_idx = random.randint(0, len(self.city_images) - 1)\n",
        "        city_img = Image.open(self.city_images[rand_idx]).convert('RGB').resize((1280, 720), Image.BILINEAR)\n",
        "\n",
        "        gta_t = self.normalize(self.to_tensor(gta_img))\n",
        "        city_t = self.normalize(self.to_tensor(city_img))\n",
        "\n",
        "        mask_np = np.array(gta_mask)\n",
        "        gta_lbl = np.full(mask_np.shape, 255, dtype=np.uint8)\n",
        "        for k, v in self.id_mapping.items(): gta_lbl[mask_np == k] = v\n",
        "\n",
        "        return gta_t, torch.from_numpy(gta_lbl).long(), city_t\n",
        "\n",
        "# --- TRAINING LOOP ---\n",
        "print(\"Continuing Training (Epochs 16-30)...\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18').to(DEVICE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "ce_criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "dice_criterion = DiceLoss(num_classes=19, ignore_index=255)\n",
        "\n",
        "# Load the previous session\n",
        "if os.path.exists(PRETRAINED_PATH):\n",
        "    print(f\"Loading previous best: {PRETRAINED_PATH}\")\n",
        "    checkpoint = torch.load(PRETRAINED_PATH, map_location=DEVICE)\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        model.load_state_dict(checkpoint)\n",
        "else:\n",
        "    print(\"Error: Previous model not found.\")\n",
        "    sys.exit()\n",
        "\n",
        "dataset = GTA5_City_Dataset(GTA_PATH, CITYSCAPES_PATH)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Resume loop\n",
        "start_epoch = 15\n",
        "\n",
        "print(f\"Training from Epoch {start_epoch} to {TOTAL_EPOCHS}...\")\n",
        "\n",
        "for epoch in range(start_epoch, TOTAL_EPOCHS):\n",
        "    for i, (gta_img, gta_lbl, city_img) in enumerate(loader):\n",
        "        gta_img, gta_lbl, city_img = gta_img.to(DEVICE), gta_lbl.to(DEVICE), city_img.to(DEVICE)\n",
        "\n",
        "        # 1. Pseudo-Labeling\n",
        "        with torch.no_grad():\n",
        "            city_out = model(city_img)\n",
        "            if isinstance(city_out, tuple): city_out = city_out[0]\n",
        "            city_pseudo_lbl = torch.argmax(city_out, dim=1)\n",
        "\n",
        "        # 2. Mix\n",
        "        batch_size = gta_img.shape[0]\n",
        "        mixed_img = city_img.clone()\n",
        "        mixed_lbl = city_pseudo_lbl.clone()\n",
        "        for b in range(batch_size):\n",
        "            classes = torch.unique(gta_lbl[b])\n",
        "            classes = classes[classes != 255]\n",
        "            if len(classes) > 0:\n",
        "                perm = torch.randperm(len(classes))\n",
        "                sel = classes[perm[:(len(classes)+1)//2]]\n",
        "                mask = torch.zeros_like(gta_lbl[b]).bool()\n",
        "                for c in sel: mask = mask | (gta_lbl[b] == c)\n",
        "                mixed_img[b, :, mask] = gta_img[b, :, mask]\n",
        "                mixed_lbl[b, mask] = gta_lbl[b, mask]\n",
        "\n",
        "        # 3. Forward\n",
        "        out = model(mixed_img)\n",
        "\n",
        "        # 4. Hybrid Loss\n",
        "        loss_ce = ce_criterion(out[0], mixed_lbl)\n",
        "        loss_dice = dice_criterion(out[0], mixed_lbl)\n",
        "\n",
        "        total_loss = loss_ce + loss_dice\n",
        "        total_loss += 0.1 * ce_criterion(out[1], mixed_lbl) + 0.1 * ce_criterion(out[2], mixed_lbl)\n",
        "\n",
        "        total_loss = total_loss / ACCUM_STEPS\n",
        "        total_loss.backward()\n",
        "\n",
        "        if (i + 1) % ACCUM_STEPS == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Ep {epoch+1} | It {i} | Loss: {total_loss.item() * ACCUM_STEPS:.4f}\")\n",
        "\n",
        "    # Save to NEW file\n",
        "    torch.save({'model_state_dict': model.state_dict(), 'epoch': epoch}, SAVE_PATH)\n",
        "    print(f\"Epoch {epoch+1} Saved to {SAVE_NAME}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KELfjGB43Mkr",
        "outputId": "a75e7334-2f6e-4312-ed91-a1b9dcf83ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Continuing Training (Epochs 16-30)...\n",
            "Loading previous best: /content/drive/MyDrive/semseg/bisenet_extension_final.pth\n",
            "Training from Epoch 15 to 30...\n",
            "Ep 16 | It 0 | Loss: 0.7495\n",
            "Ep 16 | It 100 | Loss: 0.6704\n",
            "Ep 16 | It 200 | Loss: 0.5989\n",
            "Ep 16 | It 300 | Loss: 0.5979\n",
            "Ep 16 | It 400 | Loss: 0.6397\n",
            "Ep 16 | It 500 | Loss: 0.6072\n",
            "Ep 16 | It 600 | Loss: 0.5751\n",
            "Epoch 16 Saved to bisenet_extension_30ep.pth\n",
            "Ep 17 | It 0 | Loss: 0.5805\n",
            "Ep 17 | It 100 | Loss: 0.7117\n",
            "Ep 17 | It 200 | Loss: 0.6065\n",
            "Ep 17 | It 300 | Loss: 0.5594\n",
            "Ep 17 | It 400 | Loss: 0.5609\n",
            "Ep 17 | It 500 | Loss: 0.7333\n",
            "Ep 17 | It 600 | Loss: 0.6689\n",
            "Epoch 17 Saved to bisenet_extension_30ep.pth\n",
            "Ep 18 | It 0 | Loss: 0.6963\n",
            "Ep 18 | It 100 | Loss: 0.7050\n",
            "Ep 18 | It 200 | Loss: 0.7120\n",
            "Ep 18 | It 300 | Loss: 0.5380\n",
            "Ep 18 | It 400 | Loss: 0.7319\n",
            "Ep 18 | It 500 | Loss: 0.5989\n",
            "Ep 18 | It 600 | Loss: 0.7979\n",
            "Epoch 18 Saved to bisenet_extension_30ep.pth\n",
            "Ep 19 | It 0 | Loss: 0.7695\n",
            "Ep 19 | It 100 | Loss: 0.6412\n",
            "Ep 19 | It 200 | Loss: 0.7053\n",
            "Ep 19 | It 300 | Loss: 0.8599\n",
            "Ep 19 | It 400 | Loss: 0.7143\n",
            "Ep 19 | It 500 | Loss: 0.5215\n",
            "Ep 19 | It 600 | Loss: 0.6152\n",
            "Epoch 19 Saved to bisenet_extension_30ep.pth\n",
            "Ep 20 | It 0 | Loss: 0.6397\n",
            "Ep 20 | It 100 | Loss: 0.5463\n",
            "Ep 20 | It 200 | Loss: 0.6739\n",
            "Ep 20 | It 300 | Loss: 0.6710\n",
            "Ep 20 | It 400 | Loss: 0.6905\n",
            "Ep 20 | It 500 | Loss: 0.6488\n",
            "Ep 20 | It 600 | Loss: 0.6379\n",
            "Epoch 20 Saved to bisenet_extension_30ep.pth\n",
            "Ep 21 | It 0 | Loss: 0.6348\n",
            "Ep 21 | It 100 | Loss: 0.6659\n",
            "Ep 21 | It 200 | Loss: 0.5735\n",
            "Ep 21 | It 300 | Loss: 0.7018\n",
            "Ep 21 | It 400 | Loss: 0.7073\n",
            "Ep 21 | It 500 | Loss: 0.5770\n",
            "Ep 21 | It 600 | Loss: 0.6014\n",
            "Epoch 21 Saved to bisenet_extension_30ep.pth\n",
            "Ep 22 | It 0 | Loss: 0.6517\n",
            "Ep 22 | It 100 | Loss: 0.5628\n",
            "Ep 22 | It 200 | Loss: 0.5802\n",
            "Ep 22 | It 300 | Loss: 0.4976\n",
            "Ep 22 | It 400 | Loss: 0.5540\n",
            "Ep 22 | It 500 | Loss: 0.6178\n",
            "Ep 22 | It 600 | Loss: 0.5235\n",
            "Epoch 22 Saved to bisenet_extension_30ep.pth\n",
            "Ep 23 | It 0 | Loss: 0.7345\n",
            "Ep 23 | It 100 | Loss: 0.6202\n",
            "Ep 23 | It 200 | Loss: 0.7250\n",
            "Ep 23 | It 300 | Loss: 0.7047\n",
            "Ep 23 | It 400 | Loss: 0.5867\n",
            "Ep 23 | It 500 | Loss: 0.6519\n",
            "Ep 23 | It 600 | Loss: 0.5973\n",
            "Epoch 23 Saved to bisenet_extension_30ep.pth\n",
            "Ep 24 | It 0 | Loss: 0.6653\n",
            "Ep 24 | It 100 | Loss: 0.5359\n",
            "Ep 24 | It 200 | Loss: 0.6326\n",
            "Ep 24 | It 300 | Loss: 0.5228\n",
            "Ep 24 | It 400 | Loss: 0.6626\n",
            "Ep 24 | It 500 | Loss: 0.6282\n",
            "Ep 24 | It 600 | Loss: 0.5589\n",
            "Epoch 24 Saved to bisenet_extension_30ep.pth\n",
            "Ep 25 | It 0 | Loss: 0.5336\n",
            "Ep 25 | It 100 | Loss: 0.6377\n",
            "Ep 25 | It 200 | Loss: 0.6309\n",
            "Ep 25 | It 300 | Loss: 0.5762\n",
            "Ep 25 | It 400 | Loss: 0.6880\n",
            "Ep 25 | It 500 | Loss: 0.5207\n",
            "Ep 25 | It 600 | Loss: 0.5331\n",
            "Epoch 25 Saved to bisenet_extension_30ep.pth\n",
            "Ep 26 | It 0 | Loss: 0.6813\n",
            "Ep 26 | It 100 | Loss: 0.6006\n",
            "Ep 26 | It 200 | Loss: 0.5650\n",
            "Ep 26 | It 300 | Loss: 0.6261\n",
            "Ep 26 | It 400 | Loss: 0.6873\n",
            "Ep 26 | It 500 | Loss: 0.6248\n",
            "Ep 26 | It 600 | Loss: 0.5653\n",
            "Epoch 26 Saved to bisenet_extension_30ep.pth\n",
            "Ep 27 | It 0 | Loss: 0.6227\n",
            "Ep 27 | It 100 | Loss: 0.5577\n",
            "Ep 27 | It 200 | Loss: 0.6712\n",
            "Ep 27 | It 300 | Loss: 0.5859\n",
            "Ep 27 | It 400 | Loss: 0.6685\n",
            "Ep 27 | It 500 | Loss: 0.5561\n",
            "Ep 27 | It 600 | Loss: 0.6195\n",
            "Epoch 27 Saved to bisenet_extension_30ep.pth\n",
            "Ep 28 | It 0 | Loss: 0.6519\n",
            "Ep 28 | It 100 | Loss: 0.5676\n",
            "Ep 28 | It 200 | Loss: 0.5885\n",
            "Ep 28 | It 300 | Loss: 0.6624\n",
            "Ep 28 | It 400 | Loss: 0.7409\n",
            "Ep 28 | It 500 | Loss: 0.5729\n",
            "Ep 28 | It 600 | Loss: 0.5691\n",
            "Epoch 28 Saved to bisenet_extension_30ep.pth\n",
            "Ep 29 | It 0 | Loss: 0.5190\n",
            "Ep 29 | It 100 | Loss: 0.5685\n",
            "Ep 29 | It 200 | Loss: 0.5749\n",
            "Ep 29 | It 300 | Loss: 0.6030\n",
            "Ep 29 | It 400 | Loss: 0.6410\n",
            "Ep 29 | It 500 | Loss: 0.6503\n",
            "Ep 29 | It 600 | Loss: 0.6449\n",
            "Epoch 29 Saved to bisenet_extension_30ep.pth\n",
            "Ep 30 | It 0 | Loss: 0.5623\n",
            "Ep 30 | It 100 | Loss: 0.5728\n",
            "Ep 30 | It 200 | Loss: 0.5584\n",
            "Ep 30 | It 300 | Loss: 0.6458\n",
            "Ep 30 | It 400 | Loss: 0.6677\n",
            "Ep 30 | It 500 | Loss: 0.6598\n",
            "Ep 30 | It 600 | Loss: 0.6296\n",
            "Epoch 30 Saved to bisenet_extension_30ep.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "SAVE_NAME = 'bisenet_extension_50ep.pth'\n",
        "# Load the 30-epoch model\n",
        "PRETRAINED_PATH = '/content/drive/MyDrive/semseg/bisenet_extension_30ep.pth'\n",
        "SAVE_PATH = f'/content/drive/MyDrive/semseg/{SAVE_NAME}'\n",
        "\n",
        "TOTAL_EPOCHS = 50    # Going from 30 -> 50\n",
        "BATCH_SIZE = 4\n",
        "ACCUM_STEPS = 2\n",
        "LR = 1e-3\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "GTA_PATH = '/content/dataset/project_data/gta5'\n",
        "CITYSCAPES_PATH = '/content/dataset/project_data/cityscapes'\n",
        "\n",
        "# --- IMPORTS ---\n",
        "if os.path.exists('/content/MLDL2024_project1'):\n",
        "    sys.path.append('/content/MLDL2024_project1')\n",
        "try:\n",
        "    from models.bisenet.build_bisenet import BiSeNet\n",
        "except ImportError:\n",
        "    print(\"Error: BiSeNet not found.\")\n",
        "\n",
        "# --- DICE LOSS ---\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, num_classes=19, smooth=1.0, ignore_index=255):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.smooth = smooth\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        target_one_hot = F.one_hot(target.clamp(0, self.num_classes-1), num_classes=self.num_classes)\n",
        "        target_one_hot = target_one_hot.permute(0, 3, 1, 2).float()\n",
        "\n",
        "        mask = (target != self.ignore_index).unsqueeze(1).float()\n",
        "        pred = pred * mask\n",
        "        target_one_hot = target_one_hot * mask\n",
        "\n",
        "        intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
        "        union = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
        "\n",
        "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
        "        return 1.0 - dice.mean()\n",
        "\n",
        "# --- DATASET ---\n",
        "class GTA5_City_Dataset(Dataset):\n",
        "    def __init__(self, gta_root, city_root):\n",
        "        self.gta_images_dir = os.path.join(gta_root, 'images')\n",
        "        self.gta_masks_dir = os.path.join(gta_root, 'labels')\n",
        "        self.gta_images = sorted(os.listdir(self.gta_images_dir))\n",
        "        self.city_images_dir = os.path.join(city_root, 'leftImg8bit', 'train')\n",
        "        self.city_images = []\n",
        "        if os.path.exists(self.city_images_dir):\n",
        "            for city in os.listdir(self.city_images_dir):\n",
        "                c_path = os.path.join(self.city_images_dir, city)\n",
        "                if os.path.isdir(c_path):\n",
        "                    for f in os.listdir(c_path):\n",
        "                        if f.endswith('_leftImg8bit.png'):\n",
        "                            self.city_images.append(os.path.join(c_path, f))\n",
        "\n",
        "        self.normalize = transforms.Compose([\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        self.id_mapping = {\n",
        "            7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 17: 5,\n",
        "            19: 6, 20: 7, 21: 8, 22: 9, 23: 10, 24: 11, 25: 12,\n",
        "            26: 13, 27: 14, 28: 15, 31: 16, 32: 17, 33: 18\n",
        "        }\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self): return len(self.gta_images)\n",
        "    def __getitem__(self, idx):\n",
        "        gta_path = os.path.join(self.gta_images_dir, self.gta_images[idx])\n",
        "        mask_path = os.path.join(self.gta_masks_dir, self.gta_images[idx])\n",
        "        gta_img = Image.open(gta_path).convert('RGB').resize((1280, 720), Image.BILINEAR)\n",
        "        gta_mask = Image.open(mask_path).resize((1280, 720), Image.NEAREST)\n",
        "\n",
        "        rand_idx = random.randint(0, len(self.city_images) - 1)\n",
        "        city_img = Image.open(self.city_images[rand_idx]).convert('RGB').resize((1280, 720), Image.BILINEAR)\n",
        "\n",
        "        gta_t = self.normalize(self.to_tensor(gta_img))\n",
        "        city_t = self.normalize(self.to_tensor(city_img))\n",
        "\n",
        "        mask_np = np.array(gta_mask)\n",
        "        gta_lbl = np.full(mask_np.shape, 255, dtype=np.uint8)\n",
        "        for k, v in self.id_mapping.items(): gta_lbl[mask_np == k] = v\n",
        "\n",
        "        return gta_t, torch.from_numpy(gta_lbl).long(), city_t\n",
        "\n",
        "# --- TRAINING LOOP ---\n",
        "print(\"Continuing Training (Epochs 31-50)...\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18').to(DEVICE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "ce_criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "dice_criterion = DiceLoss(num_classes=19, ignore_index=255)\n",
        "\n",
        "if os.path.exists(PRETRAINED_PATH):\n",
        "    print(f\"Loading previous best: {PRETRAINED_PATH}\")\n",
        "    checkpoint = torch.load(PRETRAINED_PATH, map_location=DEVICE)\n",
        "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        model.load_state_dict(checkpoint)\n",
        "else:\n",
        "    print(\"Error: Previous model not found.\")\n",
        "    sys.exit()\n",
        "\n",
        "dataset = GTA5_City_Dataset(GTA_PATH, CITYSCAPES_PATH)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "\n",
        "start_epoch = 30 # Resume from 30\n",
        "\n",
        "print(f\"Training from Epoch {start_epoch} to {TOTAL_EPOCHS}...\")\n",
        "\n",
        "for epoch in range(start_epoch, TOTAL_EPOCHS):\n",
        "    for i, (gta_img, gta_lbl, city_img) in enumerate(loader):\n",
        "        gta_img, gta_lbl, city_img = gta_img.to(DEVICE), gta_lbl.to(DEVICE), city_img.to(DEVICE)\n",
        "\n",
        "        # 1. Pseudo-Labeling\n",
        "        with torch.no_grad():\n",
        "            city_out = model(city_img)\n",
        "            if isinstance(city_out, tuple): city_out = city_out[0]\n",
        "            city_pseudo_lbl = torch.argmax(city_out, dim=1)\n",
        "\n",
        "        # 2. Mix\n",
        "        batch_size = gta_img.shape[0]\n",
        "        mixed_img = city_img.clone()\n",
        "        mixed_lbl = city_pseudo_lbl.clone()\n",
        "        for b in range(batch_size):\n",
        "            classes = torch.unique(gta_lbl[b])\n",
        "            classes = classes[classes != 255]\n",
        "            if len(classes) > 0:\n",
        "                perm = torch.randperm(len(classes))\n",
        "                sel = classes[perm[:(len(classes)+1)//2]]\n",
        "                mask = torch.zeros_like(gta_lbl[b]).bool()\n",
        "                for c in sel: mask = mask | (gta_lbl[b] == c)\n",
        "                mixed_img[b, :, mask] = gta_img[b, :, mask]\n",
        "                mixed_lbl[b, mask] = gta_lbl[b, mask]\n",
        "\n",
        "        # 3. Forward\n",
        "        out = model(mixed_img)\n",
        "\n",
        "        # 4. Hybrid Loss\n",
        "        loss_ce = ce_criterion(out[0], mixed_lbl)\n",
        "        loss_dice = dice_criterion(out[0], mixed_lbl)\n",
        "\n",
        "        total_loss = loss_ce + loss_dice\n",
        "        total_loss += 0.1 * ce_criterion(out[1], mixed_lbl) + 0.1 * ce_criterion(out[2], mixed_lbl)\n",
        "\n",
        "        total_loss = total_loss / ACCUM_STEPS\n",
        "        total_loss.backward()\n",
        "\n",
        "        if (i + 1) % ACCUM_STEPS == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Ep {epoch+1} | It {i} | Loss: {total_loss.item() * ACCUM_STEPS:.4f}\")\n",
        "\n",
        "    torch.save({'model_state_dict': model.state_dict(), 'epoch': epoch}, SAVE_PATH)\n",
        "    print(f\"Epoch {epoch+1} Saved to {SAVE_NAME}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRrO0t4eZTFW",
        "outputId": "da406db7-c0f3-40fe-817d-09d7d3b3f0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Continuing Training (Epochs 31-50)...\n",
            "Loading previous best: /content/drive/MyDrive/semseg/bisenet_extension_30ep.pth\n",
            "Training from Epoch 30 to 50...\n",
            "Ep 31 | It 0 | Loss: 0.7069\n",
            "Ep 31 | It 100 | Loss: 0.6903\n",
            "Ep 31 | It 200 | Loss: 0.5758\n",
            "Ep 31 | It 300 | Loss: 0.6704\n",
            "Ep 31 | It 400 | Loss: 0.6485\n",
            "Ep 31 | It 500 | Loss: 0.6363\n",
            "Ep 31 | It 600 | Loss: 0.6646\n",
            "Epoch 31 Saved to bisenet_extension_50ep.pth\n",
            "Ep 32 | It 0 | Loss: 0.6212\n",
            "Ep 32 | It 100 | Loss: 0.6226\n",
            "Ep 32 | It 200 | Loss: 0.7419\n",
            "Ep 32 | It 300 | Loss: 0.5441\n",
            "Ep 32 | It 400 | Loss: 0.5918\n",
            "Ep 32 | It 500 | Loss: 0.5758\n",
            "Ep 32 | It 600 | Loss: 0.6510\n",
            "Epoch 32 Saved to bisenet_extension_50ep.pth\n",
            "Ep 33 | It 0 | Loss: 0.5684\n",
            "Ep 33 | It 100 | Loss: 0.6872\n",
            "Ep 33 | It 200 | Loss: 0.6759\n",
            "Ep 33 | It 300 | Loss: 0.5872\n",
            "Ep 33 | It 400 | Loss: 0.5764\n",
            "Ep 33 | It 500 | Loss: 0.6471\n",
            "Ep 33 | It 600 | Loss: 0.5845\n",
            "Epoch 33 Saved to bisenet_extension_50ep.pth\n",
            "Ep 34 | It 0 | Loss: 0.5457\n",
            "Ep 34 | It 100 | Loss: 0.5095\n",
            "Ep 34 | It 200 | Loss: 0.4730\n",
            "Ep 34 | It 300 | Loss: 0.8076\n",
            "Ep 34 | It 400 | Loss: 0.6456\n",
            "Ep 34 | It 500 | Loss: 0.6711\n",
            "Ep 34 | It 600 | Loss: 0.5512\n",
            "Epoch 34 Saved to bisenet_extension_50ep.pth\n",
            "Ep 35 | It 0 | Loss: 0.4914\n",
            "Ep 35 | It 100 | Loss: 0.6184\n",
            "Ep 35 | It 200 | Loss: 0.5154\n",
            "Ep 35 | It 300 | Loss: 0.5285\n",
            "Ep 35 | It 400 | Loss: 0.5593\n",
            "Ep 35 | It 500 | Loss: 0.5811\n",
            "Ep 35 | It 600 | Loss: 0.6576\n",
            "Epoch 35 Saved to bisenet_extension_50ep.pth\n",
            "Ep 36 | It 0 | Loss: 0.6554\n",
            "Ep 36 | It 100 | Loss: 0.5856\n",
            "Ep 36 | It 200 | Loss: 0.6687\n",
            "Ep 36 | It 300 | Loss: 0.6234\n",
            "Ep 36 | It 400 | Loss: 0.6358\n",
            "Ep 36 | It 500 | Loss: 0.6026\n",
            "Ep 36 | It 600 | Loss: 0.5786\n",
            "Epoch 36 Saved to bisenet_extension_50ep.pth\n",
            "Ep 37 | It 0 | Loss: 0.6425\n",
            "Ep 37 | It 100 | Loss: 0.6203\n",
            "Ep 37 | It 200 | Loss: 0.6035\n",
            "Ep 37 | It 300 | Loss: 0.6045\n",
            "Ep 37 | It 400 | Loss: 0.5717\n",
            "Ep 37 | It 500 | Loss: 0.5409\n",
            "Ep 37 | It 600 | Loss: 0.5598\n",
            "Epoch 37 Saved to bisenet_extension_50ep.pth\n",
            "Ep 38 | It 0 | Loss: 0.6197\n",
            "Ep 38 | It 100 | Loss: 0.6860\n",
            "Ep 38 | It 200 | Loss: 0.6752\n",
            "Ep 38 | It 300 | Loss: 0.6407\n",
            "Ep 38 | It 400 | Loss: 0.6725\n",
            "Ep 38 | It 500 | Loss: 0.5082\n",
            "Ep 38 | It 600 | Loss: 0.6808\n",
            "Epoch 38 Saved to bisenet_extension_50ep.pth\n",
            "Ep 39 | It 0 | Loss: 0.7697\n",
            "Ep 39 | It 100 | Loss: 0.6864\n",
            "Ep 39 | It 200 | Loss: 0.5236\n",
            "Ep 39 | It 300 | Loss: 0.5324\n",
            "Ep 39 | It 400 | Loss: 0.6947\n",
            "Ep 39 | It 500 | Loss: 0.5594\n",
            "Ep 39 | It 600 | Loss: 0.5902\n",
            "Epoch 39 Saved to bisenet_extension_50ep.pth\n",
            "Ep 40 | It 0 | Loss: 0.7009\n",
            "Ep 40 | It 100 | Loss: 0.6095\n",
            "Ep 40 | It 200 | Loss: 0.5847\n",
            "Ep 40 | It 300 | Loss: 0.7144\n",
            "Ep 40 | It 400 | Loss: 0.6670\n",
            "Ep 40 | It 500 | Loss: 0.5644\n",
            "Ep 40 | It 600 | Loss: 0.7831\n",
            "Epoch 40 Saved to bisenet_extension_50ep.pth\n",
            "Ep 41 | It 0 | Loss: 0.4862\n",
            "Ep 41 | It 100 | Loss: 0.5269\n",
            "Ep 41 | It 200 | Loss: 0.5726\n",
            "Ep 41 | It 300 | Loss: 0.6105\n",
            "Ep 41 | It 400 | Loss: 0.5727\n",
            "Ep 41 | It 500 | Loss: 0.9102\n",
            "Ep 41 | It 600 | Loss: 0.5935\n",
            "Epoch 41 Saved to bisenet_extension_50ep.pth\n",
            "Ep 42 | It 0 | Loss: 0.5902\n",
            "Ep 42 | It 100 | Loss: 0.6135\n",
            "Ep 42 | It 200 | Loss: 0.5633\n",
            "Ep 42 | It 300 | Loss: 0.6176\n",
            "Ep 42 | It 400 | Loss: 0.6478\n",
            "Ep 42 | It 500 | Loss: 0.6651\n",
            "Ep 42 | It 600 | Loss: 0.5814\n",
            "Epoch 42 Saved to bisenet_extension_50ep.pth\n",
            "Ep 43 | It 0 | Loss: 0.5133\n",
            "Ep 43 | It 100 | Loss: 0.6041\n",
            "Ep 43 | It 200 | Loss: 0.6677\n",
            "Ep 43 | It 300 | Loss: 0.6642\n",
            "Ep 43 | It 400 | Loss: 0.7107\n",
            "Ep 43 | It 500 | Loss: 0.5691\n",
            "Ep 43 | It 600 | Loss: 0.5734\n",
            "Epoch 43 Saved to bisenet_extension_50ep.pth\n",
            "Ep 44 | It 0 | Loss: 0.5650\n",
            "Ep 44 | It 100 | Loss: 0.6752\n",
            "Ep 44 | It 200 | Loss: 0.6922\n",
            "Ep 44 | It 300 | Loss: 0.7139\n",
            "Ep 44 | It 400 | Loss: 0.6074\n",
            "Ep 44 | It 500 | Loss: 0.6320\n",
            "Ep 44 | It 600 | Loss: 0.6148\n",
            "Epoch 44 Saved to bisenet_extension_50ep.pth\n",
            "Ep 45 | It 0 | Loss: 0.5198\n",
            "Ep 45 | It 100 | Loss: 0.5832\n",
            "Ep 45 | It 200 | Loss: 0.6835\n",
            "Ep 45 | It 300 | Loss: 0.6277\n",
            "Ep 45 | It 400 | Loss: 0.6153\n",
            "Ep 45 | It 500 | Loss: 0.6292\n",
            "Ep 45 | It 600 | Loss: 0.6233\n",
            "Epoch 45 Saved to bisenet_extension_50ep.pth\n",
            "Ep 46 | It 0 | Loss: 0.5709\n",
            "Ep 46 | It 100 | Loss: 0.5903\n",
            "Ep 46 | It 200 | Loss: 0.6264\n",
            "Ep 46 | It 300 | Loss: 0.5500\n",
            "Ep 46 | It 400 | Loss: 0.5875\n",
            "Ep 46 | It 500 | Loss: 0.5528\n",
            "Ep 46 | It 600 | Loss: 0.6217\n",
            "Epoch 46 Saved to bisenet_extension_50ep.pth\n",
            "Ep 47 | It 0 | Loss: 0.5823\n",
            "Ep 47 | It 100 | Loss: 0.5821\n",
            "Ep 47 | It 200 | Loss: 0.6338\n",
            "Ep 47 | It 300 | Loss: 0.5979\n",
            "Ep 47 | It 400 | Loss: 0.6443\n",
            "Ep 47 | It 500 | Loss: 0.7644\n",
            "Ep 47 | It 600 | Loss: 0.5570\n",
            "Epoch 47 Saved to bisenet_extension_50ep.pth\n",
            "Ep 48 | It 0 | Loss: 0.6561\n",
            "Ep 48 | It 100 | Loss: 0.5843\n",
            "Ep 48 | It 200 | Loss: 0.6263\n",
            "Ep 48 | It 300 | Loss: 0.6927\n",
            "Ep 48 | It 400 | Loss: 0.5375\n",
            "Ep 48 | It 500 | Loss: 0.6242\n",
            "Ep 48 | It 600 | Loss: 0.5641\n",
            "Epoch 48 Saved to bisenet_extension_50ep.pth\n",
            "Ep 49 | It 0 | Loss: 0.6368\n",
            "Ep 49 | It 100 | Loss: 0.6168\n",
            "Ep 49 | It 200 | Loss: 0.7219\n",
            "Ep 49 | It 300 | Loss: 0.5749\n",
            "Ep 49 | It 400 | Loss: 0.5631\n",
            "Ep 49 | It 500 | Loss: 0.6586\n",
            "Ep 49 | It 600 | Loss: 0.7090\n",
            "Epoch 49 Saved to bisenet_extension_50ep.pth\n",
            "Ep 50 | It 0 | Loss: 0.4243\n",
            "Ep 50 | It 100 | Loss: 0.5726\n",
            "Ep 50 | It 200 | Loss: 0.6066\n",
            "Ep 50 | It 300 | Loss: 0.6824\n",
            "Ep 50 | It 400 | Loss: 0.6202\n",
            "Ep 50 | It 500 | Loss: 0.7003\n",
            "Ep 50 | It 600 | Loss: 0.5525\n",
            "Epoch 50 Saved to bisenet_extension_50ep.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Point to the 50-epoch model\n",
        "CHECKPOINT_PATH = '/content/drive/MyDrive/semseg/bisenet_extension_50ep.pth'\n",
        "CITY_PATH = '/content/dataset/project_data/cityscapes'\n",
        "NUM_CLASSES = 19\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- IMPORTS ---\n",
        "if os.path.exists('/content/MLDL2024_project1'):\n",
        "    sys.path.append('/content/MLDL2024_project1')\n",
        "try:\n",
        "    from models.bisenet.build_bisenet import BiSeNet\n",
        "except:\n",
        "    print(\"Warning: Could not import BiSeNet directly.\")\n",
        "\n",
        "# --- DATASET ---\n",
        "class CityscapesValDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        self.img_dir = os.path.join(root, 'leftImg8bit', 'val')\n",
        "        self.lbl_dir = os.path.join(root, 'gtFine', 'val')\n",
        "        self.imgs = []\n",
        "        self.lbls = []\n",
        "        if os.path.exists(self.img_dir):\n",
        "            for city in sorted(os.listdir(self.img_dir)):\n",
        "                img_path = os.path.join(self.img_dir, city)\n",
        "                lbl_path = os.path.join(self.lbl_dir, city)\n",
        "                for f in sorted(os.listdir(img_path)):\n",
        "                    if f.endswith('_leftImg8bit.png'):\n",
        "                        self.imgs.append(os.path.join(img_path, f))\n",
        "                        self.lbls.append(os.path.join(lbl_path, f.replace('_leftImg8bit.png', '_gtFine_labelTrainIds.png')))\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((512, 1024)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    def __len__(self): return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.imgs[idx]).convert('RGB')\n",
        "        lbl = Image.open(self.lbls[idx]).resize((1024, 512), Image.NEAREST)\n",
        "        img = self.transform(img)\n",
        "        lbl = torch.from_numpy(np.array(lbl)).long()\n",
        "        return img, lbl\n",
        "\n",
        "# --- EVALUATION ---\n",
        "print(f\"Evaluating 50-Epoch Extension Model: {CHECKPOINT_PATH}\")\n",
        "model = BiSeNet(num_classes=NUM_CLASSES, context_path='resnet18').to(DEVICE)\n",
        "\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
        "    if isinstance(ckpt, dict) and 'model_state_dict' in ckpt:\n",
        "        model.load_state_dict(ckpt['model_state_dict'])\n",
        "    else:\n",
        "        model.load_state_dict(ckpt)\n",
        "    print(\"Model loaded successfully.\")\n",
        "else:\n",
        "    print(\"Error: Checkpoint not found.\")\n",
        "    sys.exit()\n",
        "\n",
        "model.eval()\n",
        "loader = DataLoader(CityscapesValDataset(CITY_PATH), batch_size=1, shuffle=False, num_workers=2)\n",
        "hist = np.zeros((NUM_CLASSES, NUM_CLASSES))\n",
        "\n",
        "print(\"Processing images...\")\n",
        "with torch.no_grad():\n",
        "    for img, lbl in tqdm(loader):\n",
        "        img = img.to(DEVICE)\n",
        "        output = model(img)\n",
        "        if isinstance(output, tuple): output = output[0]\n",
        "        preds = torch.argmax(output, dim=1).cpu().numpy()\n",
        "        lbl = lbl.numpy()\n",
        "\n",
        "        mask = (lbl >= 0) & (lbl < NUM_CLASSES)\n",
        "        hist += np.bincount(\n",
        "            NUM_CLASSES * lbl[mask].astype(int) + preds[mask],\n",
        "            minlength=NUM_CLASSES ** 2\n",
        "        ).reshape(NUM_CLASSES, NUM_CLASSES)\n",
        "\n",
        "iou = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
        "miou = np.nanmean(iou) * 100\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"FINAL SCORE (Hybrid Loss - 50 Epochs): {miou:.2f}%\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "CLASSES = [\"Road\", \"Sidewalk\", \"Building\", \"Wall\", \"Fence\", \"Pole\", \"Traffic Light\", \"Traffic Sign\", \"Vegetation\", \"Terrain\", \"Sky\", \"Person\", \"Rider\", \"Car\", \"Truck\", \"Bus\", \"Train\", \"Motorcycle\", \"Bicycle\"]\n",
        "for i, name in enumerate(CLASSES):\n",
        "    print(f\"{name:15s}: {iou[i]*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVGKGf7fINnz",
        "outputId": "67ec68c1-5640-400d-ac18-16944726eef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating 50-Epoch Extension Model: /content/drive/MyDrive/semseg/bisenet_extension_50ep.pth\n",
            "Model loaded successfully.\n",
            "Processing images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [01:08<00:00,  7.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "FINAL SCORE (Hybrid Loss - 50 Epochs): 28.23%\n",
            "==============================\n",
            "Road           : 88.75%\n",
            "Sidewalk       : 33.53%\n",
            "Building       : 70.65%\n",
            "Wall           : 20.21%\n",
            "Fence          : 16.08%\n",
            "Pole           : 21.74%\n",
            "Traffic Light  : 20.19%\n",
            "Traffic Sign   : 10.34%\n",
            "Vegetation     : 71.40%\n",
            "Terrain        : 13.73%\n",
            "Sky            : 49.09%\n",
            "Person         : 37.50%\n",
            "Rider          : 0.00%\n",
            "Car            : 71.37%\n",
            "Truck          : 10.69%\n",
            "Bus            : 1.02%\n",
            "Train          : 0.00%\n",
            "Motorcycle     : 0.00%\n",
            "Bicycle        : 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}