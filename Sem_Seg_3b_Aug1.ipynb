{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdc5lq5EpkCF",
        "outputId": "89667625-3913-44c8-873d-a0d08e1f0129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'temp_repo'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "Receiving objects: 100% (34/34), 11.29 KiB | 11.29 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "remote: Total 34 (delta 9), reused 3 (delta 3), pack-reused 13 (from 1)\u001b[K\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists('/content/models'):\n",
        "    !git clone https://github.com/Gabrysse/MLDL2024_project1.git temp_repo\n",
        "    shutil.copytree('temp_repo/models', '/content/models')\n",
        "    shutil.rmtree('temp_repo')\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/semseg/project_data.zip'\n",
        "\n",
        "if not os.path.exists('/content/dataset/project_data/gta5'):\n",
        "    if not os.path.exists('/content/dataset'): os.makedirs('/content/dataset')\n",
        "\n",
        "    if os.path.exists(zip_path):\n",
        "        shutil.unpack_archive(zip_path, '/content/dataset')\n",
        "    else:\n",
        "        print(f\"Error: Zip file not found at {zip_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. SETUP & IMPORTS ---\n",
        "print(\"Setting up environment...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Restore Model Code\n",
        "if not os.path.exists('/content/models'):\n",
        "    print(\"Model code missing. Restoring...\")\n",
        "    !git clone https://github.com/Gabrysse/MLDL2024_project1.git temp_repo\n",
        "    shutil.copytree('temp_repo/models', '/content/models')\n",
        "    shutil.rmtree('temp_repo')\n",
        "\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "\n",
        "# --- 2. CONFIGURATION ---\n",
        "CHECKPOINT_NAME = 'bisenet_aug1_checkpoint.pth'\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 8\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DATASET_DIR = '/content/dataset'\n",
        "GTA_PATH = os.path.join(DATASET_DIR, 'project_data', 'gta5')\n",
        "ZIP_PATH = '/content/drive/MyDrive/semseg/project_data.zip'\n",
        "\n",
        "# --- 3. DATASET CHECK ---\n",
        "if not os.path.exists(GTA_PATH):\n",
        "    print(\"Dataset not found in /content/dataset. Checking zip...\")\n",
        "    if not os.path.exists(DATASET_DIR): os.makedirs(DATASET_DIR)\n",
        "\n",
        "    if os.path.exists(ZIP_PATH):\n",
        "        print(\"Unzipping dataset...\")\n",
        "        shutil.unpack_archive(ZIP_PATH, DATASET_DIR)\n",
        "        print(\"Dataset extracted.\")\n",
        "    else:\n",
        "        print(f\"Critical Error: Zip file not found at {ZIP_PATH}\")\n",
        "        sys.exit()\n",
        "else:\n",
        "    print(\"Dataset ready.\")\n",
        "\n",
        "# --- 4. DATASET CLASS (AUG 1 ONLY) ---\n",
        "class GTA5Aug1Dataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.images_dir = os.path.join(root_dir, 'images')\n",
        "        self.masks_dir = os.path.join(root_dir, 'labels')\n",
        "        self.images = sorted(os.listdir(self.images_dir))\n",
        "        self.normalize = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        self.id_mapping = {\n",
        "            7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 17: 5,\n",
        "            19: 6, 20: 7, 21: 8, 22: 9, 23: 10, 24: 11, 25: 12,\n",
        "            26: 13, 27: 14, 28: 15, 31: 16, 32: 17, 33: 18\n",
        "        }\n",
        "\n",
        "    def __len__(self): return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.images_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.masks_dir, self.images[idx])\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB').resize((1280, 720), Image.BILINEAR)\n",
        "        mask = Image.open(mask_path).resize((1280, 720), Image.NEAREST)\n",
        "\n",
        "        # AUG 1 ONLY: Random Flip\n",
        "        if random.random() > 0.5:\n",
        "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            mask = mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "        image = self.normalize(image)\n",
        "        mask_np = np.array(mask)\n",
        "        target_mask = np.full(mask_np.shape, 255, dtype=np.uint8)\n",
        "        for k, v in self.id_mapping.items(): target_mask[mask_np == k] = v\n",
        "        return image, torch.from_numpy(target_mask).long()\n",
        "\n",
        "# --- 5. TRAINING LOOP ---\n",
        "print(f\"Starting Training for {CHECKPOINT_NAME}...\")\n",
        "print(f\"Batch Size: {BATCH_SIZE} | Device: {DEVICE}\")\n",
        "\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18').to(DEVICE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "dataset = GTA5Aug1Dataset(GTA_PATH)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "save_path = f'/content/drive/MyDrive/{CHECKPOINT_NAME}'\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    for i, (img, lbl) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(img.to(DEVICE))\n",
        "        loss = criterion(out[0], lbl.to(DEVICE)) + 0.1 * criterion(out[1], lbl.to(DEVICE)) + 0.1 * criterion(out[2], lbl.to(DEVICE))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{EPOCHS}] Step [{i}/{len(loader)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Save EVERY epoch\n",
        "    torch.save({'model_state_dict': model.state_dict()}, save_path)\n",
        "    print(f\"Epoch {epoch+1} Saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIJxAekKw9uA",
        "outputId": "428e3f6f-1a35-4035-d969-afb0d6110664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up environment...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset ready.\n",
            "Starting Training for bisenet_aug1_checkpoint.pth...\n",
            "Batch Size: 8 | Device: cuda\n",
            "Epoch [1/50] Step [0/313] Loss: 3.9578\n",
            "Epoch [1/50] Step [50/313] Loss: 1.1189\n",
            "Epoch [1/50] Step [100/313] Loss: 0.6854\n",
            "Epoch [1/50] Step [150/313] Loss: 0.6066\n",
            "Epoch [1/50] Step [200/313] Loss: 0.5280\n",
            "Epoch [1/50] Step [250/313] Loss: 0.5274\n",
            "Epoch [1/50] Step [300/313] Loss: 0.4635\n",
            "Epoch 1 Saved.\n",
            "Epoch [2/50] Step [0/313] Loss: 0.5184\n",
            "Epoch [2/50] Step [50/313] Loss: 0.5624\n",
            "Epoch [2/50] Step [100/313] Loss: 0.3988\n",
            "Epoch [2/50] Step [150/313] Loss: 0.5057\n",
            "Epoch [2/50] Step [200/313] Loss: 0.4064\n",
            "Epoch [2/50] Step [250/313] Loss: 0.3651\n",
            "Epoch [2/50] Step [300/313] Loss: 0.4099\n",
            "Epoch 2 Saved.\n",
            "Epoch [3/50] Step [0/313] Loss: 0.3623\n",
            "Epoch [3/50] Step [50/313] Loss: 0.3850\n",
            "Epoch [3/50] Step [100/313] Loss: 0.3942\n",
            "Epoch [3/50] Step [150/313] Loss: 0.3693\n",
            "Epoch [3/50] Step [200/313] Loss: 0.3251\n",
            "Epoch [3/50] Step [250/313] Loss: 0.3370\n",
            "Epoch [3/50] Step [300/313] Loss: 0.2811\n",
            "Epoch 3 Saved.\n",
            "Epoch [4/50] Step [0/313] Loss: 0.4498\n",
            "Epoch [4/50] Step [50/313] Loss: 0.3113\n",
            "Epoch [4/50] Step [100/313] Loss: 0.2875\n",
            "Epoch [4/50] Step [150/313] Loss: 0.3508\n",
            "Epoch [4/50] Step [200/313] Loss: 0.3368\n",
            "Epoch [4/50] Step [250/313] Loss: 0.3465\n",
            "Epoch [4/50] Step [300/313] Loss: 0.3242\n",
            "Epoch 4 Saved.\n",
            "Epoch [5/50] Step [0/313] Loss: 0.2927\n",
            "Epoch [5/50] Step [50/313] Loss: 0.2616\n",
            "Epoch [5/50] Step [100/313] Loss: 0.3431\n",
            "Epoch [5/50] Step [150/313] Loss: 0.2881\n",
            "Epoch [5/50] Step [200/313] Loss: 0.3225\n",
            "Epoch [5/50] Step [250/313] Loss: 0.2892\n",
            "Epoch [5/50] Step [300/313] Loss: 0.3391\n",
            "Epoch 5 Saved.\n",
            "Epoch [6/50] Step [0/313] Loss: 0.3691\n",
            "Epoch [6/50] Step [50/313] Loss: 0.2966\n",
            "Epoch [6/50] Step [100/313] Loss: 0.2945\n",
            "Epoch [6/50] Step [150/313] Loss: 0.3127\n",
            "Epoch [6/50] Step [200/313] Loss: 0.2396\n",
            "Epoch [6/50] Step [250/313] Loss: 0.2913\n",
            "Epoch [6/50] Step [300/313] Loss: 0.2690\n",
            "Epoch 6 Saved.\n",
            "Epoch [7/50] Step [0/313] Loss: 0.2729\n",
            "Epoch [7/50] Step [50/313] Loss: 0.2370\n",
            "Epoch [7/50] Step [100/313] Loss: 0.3313\n",
            "Epoch [7/50] Step [150/313] Loss: 0.3043\n",
            "Epoch [7/50] Step [200/313] Loss: 0.2531\n",
            "Epoch [7/50] Step [250/313] Loss: 0.2994\n",
            "Epoch [7/50] Step [300/313] Loss: 0.2489\n",
            "Epoch 7 Saved.\n",
            "Epoch [8/50] Step [0/313] Loss: 0.2370\n",
            "Epoch [8/50] Step [50/313] Loss: 0.3172\n",
            "Epoch [8/50] Step [100/313] Loss: 0.2540\n",
            "Epoch [8/50] Step [150/313] Loss: 0.2523\n",
            "Epoch [8/50] Step [200/313] Loss: 0.2649\n",
            "Epoch [8/50] Step [250/313] Loss: 0.2624\n",
            "Epoch [8/50] Step [300/313] Loss: 0.2144\n",
            "Epoch 8 Saved.\n",
            "Epoch [9/50] Step [0/313] Loss: 0.2593\n",
            "Epoch [9/50] Step [50/313] Loss: 0.2188\n",
            "Epoch [9/50] Step [100/313] Loss: 0.2375\n",
            "Epoch [9/50] Step [150/313] Loss: 0.2746\n",
            "Epoch [9/50] Step [200/313] Loss: 0.2121\n",
            "Epoch [9/50] Step [250/313] Loss: 0.2148\n",
            "Epoch [9/50] Step [300/313] Loss: 0.2044\n",
            "Epoch 9 Saved.\n",
            "Epoch [10/50] Step [0/313] Loss: 0.2068\n",
            "Epoch [10/50] Step [50/313] Loss: 0.2348\n",
            "Epoch [10/50] Step [100/313] Loss: 0.2121\n",
            "Epoch [10/50] Step [150/313] Loss: 0.2526\n",
            "Epoch [10/50] Step [200/313] Loss: 0.2255\n",
            "Epoch [10/50] Step [250/313] Loss: 0.2550\n",
            "Epoch [10/50] Step [300/313] Loss: 0.2432\n",
            "Epoch 10 Saved.\n",
            "Epoch [11/50] Step [0/313] Loss: 0.2474\n",
            "Epoch [11/50] Step [50/313] Loss: 0.2846\n",
            "Epoch [11/50] Step [100/313] Loss: 0.2445\n",
            "Epoch [11/50] Step [150/313] Loss: 0.2002\n",
            "Epoch [11/50] Step [200/313] Loss: 0.2223\n",
            "Epoch [11/50] Step [250/313] Loss: 0.2105\n",
            "Epoch [11/50] Step [300/313] Loss: 0.2224\n",
            "Epoch 11 Saved.\n",
            "Epoch [12/50] Step [0/313] Loss: 0.2301\n",
            "Epoch [12/50] Step [50/313] Loss: 0.2426\n",
            "Epoch [12/50] Step [100/313] Loss: 0.2220\n",
            "Epoch [12/50] Step [150/313] Loss: 0.2474\n",
            "Epoch [12/50] Step [200/313] Loss: 0.2083\n",
            "Epoch [12/50] Step [250/313] Loss: 0.2180\n",
            "Epoch [12/50] Step [300/313] Loss: 0.2138\n",
            "Epoch 12 Saved.\n",
            "Epoch [13/50] Step [0/313] Loss: 0.2082\n",
            "Epoch [13/50] Step [50/313] Loss: 0.2096\n",
            "Epoch [13/50] Step [100/313] Loss: 0.2029\n",
            "Epoch [13/50] Step [150/313] Loss: 0.1973\n",
            "Epoch [13/50] Step [200/313] Loss: 0.2549\n",
            "Epoch [13/50] Step [250/313] Loss: 0.1902\n",
            "Epoch [13/50] Step [300/313] Loss: 0.2271\n",
            "Epoch 13 Saved.\n",
            "Epoch [14/50] Step [0/313] Loss: 0.2074\n",
            "Epoch [14/50] Step [50/313] Loss: 0.2033\n",
            "Epoch [14/50] Step [100/313] Loss: 0.2346\n",
            "Epoch [14/50] Step [150/313] Loss: 0.2267\n",
            "Epoch [14/50] Step [200/313] Loss: 0.2306\n",
            "Epoch [14/50] Step [250/313] Loss: 0.2027\n",
            "Epoch [14/50] Step [300/313] Loss: 0.2110\n",
            "Epoch 14 Saved.\n",
            "Epoch [15/50] Step [0/313] Loss: 0.1832\n",
            "Epoch [15/50] Step [50/313] Loss: 0.1708\n",
            "Epoch [15/50] Step [100/313] Loss: 0.1960\n",
            "Epoch [15/50] Step [150/313] Loss: 0.2190\n",
            "Epoch [15/50] Step [200/313] Loss: 0.1871\n",
            "Epoch [15/50] Step [250/313] Loss: 0.1981\n",
            "Epoch [15/50] Step [300/313] Loss: 0.2149\n",
            "Epoch 15 Saved.\n",
            "Epoch [16/50] Step [0/313] Loss: 0.1947\n",
            "Epoch [16/50] Step [50/313] Loss: 0.2103\n",
            "Epoch [16/50] Step [100/313] Loss: 0.2001\n",
            "Epoch [16/50] Step [150/313] Loss: 0.1547\n",
            "Epoch [16/50] Step [200/313] Loss: 0.1925\n",
            "Epoch [16/50] Step [250/313] Loss: 0.1852\n",
            "Epoch [16/50] Step [300/313] Loss: 0.2281\n",
            "Epoch 16 Saved.\n",
            "Epoch [17/50] Step [0/313] Loss: 0.2075\n",
            "Epoch [17/50] Step [50/313] Loss: 0.1886\n",
            "Epoch [17/50] Step [100/313] Loss: 0.2082\n",
            "Epoch [17/50] Step [150/313] Loss: 0.2182\n",
            "Epoch [17/50] Step [200/313] Loss: 0.1889\n",
            "Epoch [17/50] Step [250/313] Loss: 0.2333\n",
            "Epoch [17/50] Step [300/313] Loss: 0.1968\n",
            "Epoch 17 Saved.\n",
            "Epoch [18/50] Step [0/313] Loss: 0.2360\n",
            "Epoch [18/50] Step [50/313] Loss: 0.2287\n",
            "Epoch [18/50] Step [100/313] Loss: 0.1864\n",
            "Epoch [18/50] Step [150/313] Loss: 0.1938\n",
            "Epoch [18/50] Step [200/313] Loss: 0.2160\n",
            "Epoch [18/50] Step [250/313] Loss: 0.1861\n",
            "Epoch [18/50] Step [300/313] Loss: 0.1692\n",
            "Epoch 18 Saved.\n",
            "Epoch [19/50] Step [0/313] Loss: 0.2302\n",
            "Epoch [19/50] Step [50/313] Loss: 0.2048\n",
            "Epoch [19/50] Step [100/313] Loss: 0.2059\n",
            "Epoch [19/50] Step [150/313] Loss: 0.1921\n",
            "Epoch [19/50] Step [200/313] Loss: 0.2069\n",
            "Epoch [19/50] Step [250/313] Loss: 0.2054\n",
            "Epoch [19/50] Step [300/313] Loss: 0.1778\n",
            "Epoch 19 Saved.\n",
            "Epoch [20/50] Step [0/313] Loss: 0.1572\n",
            "Epoch [20/50] Step [50/313] Loss: 0.1955\n",
            "Epoch [20/50] Step [100/313] Loss: 0.2037\n",
            "Epoch [20/50] Step [150/313] Loss: 0.1892\n",
            "Epoch [20/50] Step [200/313] Loss: 0.2352\n",
            "Epoch [20/50] Step [250/313] Loss: 0.1786\n",
            "Epoch [20/50] Step [300/313] Loss: 0.1903\n",
            "Epoch 20 Saved.\n",
            "Epoch [21/50] Step [0/313] Loss: 0.1557\n",
            "Epoch [21/50] Step [50/313] Loss: 0.2045\n",
            "Epoch [21/50] Step [100/313] Loss: 0.1895\n",
            "Epoch [21/50] Step [150/313] Loss: 0.1745\n",
            "Epoch [21/50] Step [200/313] Loss: 0.1798\n",
            "Epoch [21/50] Step [250/313] Loss: 0.1857\n",
            "Epoch [21/50] Step [300/313] Loss: 0.2211\n",
            "Epoch 21 Saved.\n",
            "Epoch [22/50] Step [0/313] Loss: 0.1905\n",
            "Epoch [22/50] Step [50/313] Loss: 0.2378\n",
            "Epoch [22/50] Step [100/313] Loss: 0.1776\n",
            "Epoch [22/50] Step [150/313] Loss: 0.1883\n",
            "Epoch [22/50] Step [200/313] Loss: 0.1825\n",
            "Epoch [22/50] Step [250/313] Loss: 0.1855\n",
            "Epoch [22/50] Step [300/313] Loss: 0.1972\n",
            "Epoch 22 Saved.\n",
            "Epoch [23/50] Step [0/313] Loss: 0.2407\n",
            "Epoch [23/50] Step [50/313] Loss: 0.1825\n",
            "Epoch [23/50] Step [100/313] Loss: 0.1946\n",
            "Epoch [23/50] Step [150/313] Loss: 0.1741\n",
            "Epoch [23/50] Step [200/313] Loss: 0.1816\n",
            "Epoch [23/50] Step [250/313] Loss: 0.1900\n",
            "Epoch [23/50] Step [300/313] Loss: 0.1758\n",
            "Epoch 23 Saved.\n",
            "Epoch [24/50] Step [0/313] Loss: 0.1791\n",
            "Epoch [24/50] Step [50/313] Loss: 0.1564\n",
            "Epoch [24/50] Step [100/313] Loss: 0.2050\n",
            "Epoch [24/50] Step [150/313] Loss: 0.2146\n",
            "Epoch [24/50] Step [200/313] Loss: 0.1424\n",
            "Epoch [24/50] Step [250/313] Loss: 0.2060\n",
            "Epoch [24/50] Step [300/313] Loss: 0.1782\n",
            "Epoch 24 Saved.\n",
            "Epoch [25/50] Step [0/313] Loss: 0.2244\n",
            "Epoch [25/50] Step [50/313] Loss: 0.1649\n",
            "Epoch [25/50] Step [100/313] Loss: 0.1844\n",
            "Epoch [25/50] Step [150/313] Loss: 0.1723\n",
            "Epoch [25/50] Step [200/313] Loss: 0.1809\n",
            "Epoch [25/50] Step [250/313] Loss: 0.1901\n",
            "Epoch [25/50] Step [300/313] Loss: 0.1838\n",
            "Epoch 25 Saved.\n",
            "Epoch [26/50] Step [0/313] Loss: 0.1717\n",
            "Epoch [26/50] Step [50/313] Loss: 0.1689\n",
            "Epoch [26/50] Step [100/313] Loss: 0.1719\n",
            "Epoch [26/50] Step [150/313] Loss: 0.1907\n",
            "Epoch [26/50] Step [200/313] Loss: 0.1656\n",
            "Epoch [26/50] Step [250/313] Loss: 0.1868\n",
            "Epoch [26/50] Step [300/313] Loss: 0.1595\n",
            "Epoch 26 Saved.\n",
            "Epoch [27/50] Step [0/313] Loss: 0.1876\n",
            "Epoch [27/50] Step [50/313] Loss: 0.1703\n",
            "Epoch [27/50] Step [100/313] Loss: 0.1438\n",
            "Epoch [27/50] Step [150/313] Loss: 0.2172\n",
            "Epoch [27/50] Step [200/313] Loss: 0.1638\n",
            "Epoch [27/50] Step [250/313] Loss: 0.1767\n",
            "Epoch [27/50] Step [300/313] Loss: 0.1901\n",
            "Epoch 27 Saved.\n",
            "Epoch [28/50] Step [0/313] Loss: 0.1474\n",
            "Epoch [28/50] Step [50/313] Loss: 0.1569\n",
            "Epoch [28/50] Step [100/313] Loss: 0.1752\n",
            "Epoch [28/50] Step [150/313] Loss: 0.1485\n",
            "Epoch [28/50] Step [200/313] Loss: 0.1722\n",
            "Epoch [28/50] Step [250/313] Loss: 0.1724\n",
            "Epoch [28/50] Step [300/313] Loss: 0.1863\n",
            "Epoch 28 Saved.\n",
            "Epoch [29/50] Step [0/313] Loss: 0.1532\n",
            "Epoch [29/50] Step [50/313] Loss: 0.6233\n",
            "Epoch [29/50] Step [100/313] Loss: 0.2722\n",
            "Epoch [29/50] Step [150/313] Loss: 0.2089\n",
            "Epoch [29/50] Step [200/313] Loss: 0.1764\n",
            "Epoch [29/50] Step [250/313] Loss: 0.1666\n",
            "Epoch [29/50] Step [300/313] Loss: 0.2016\n",
            "Epoch 29 Saved.\n",
            "Epoch [30/50] Step [0/313] Loss: 0.1784\n",
            "Epoch [30/50] Step [50/313] Loss: 0.1927\n",
            "Epoch [30/50] Step [100/313] Loss: 0.2071\n",
            "Epoch [30/50] Step [150/313] Loss: 0.2213\n",
            "Epoch [30/50] Step [200/313] Loss: 0.1812\n",
            "Epoch [30/50] Step [250/313] Loss: 0.1681\n",
            "Epoch [30/50] Step [300/313] Loss: 0.1913\n",
            "Epoch 30 Saved.\n",
            "Epoch [31/50] Step [0/313] Loss: 0.2048\n",
            "Epoch [31/50] Step [50/313] Loss: 0.1648\n",
            "Epoch [31/50] Step [100/313] Loss: 0.1943\n",
            "Epoch [31/50] Step [150/313] Loss: 0.1582\n",
            "Epoch [31/50] Step [200/313] Loss: 0.1337\n",
            "Epoch [31/50] Step [250/313] Loss: 0.1459\n",
            "Epoch [31/50] Step [300/313] Loss: 0.1782\n",
            "Epoch 31 Saved.\n",
            "Epoch [32/50] Step [0/313] Loss: 0.1500\n",
            "Epoch [32/50] Step [50/313] Loss: 0.1552\n",
            "Epoch [32/50] Step [100/313] Loss: 0.1549\n",
            "Epoch [32/50] Step [150/313] Loss: 0.1554\n",
            "Epoch [32/50] Step [200/313] Loss: 0.1779\n",
            "Epoch [32/50] Step [250/313] Loss: 0.1568\n",
            "Epoch [32/50] Step [300/313] Loss: 0.1825\n",
            "Epoch 32 Saved.\n",
            "Epoch [33/50] Step [0/313] Loss: 0.1723\n",
            "Epoch [33/50] Step [50/313] Loss: 0.1924\n",
            "Epoch [33/50] Step [100/313] Loss: 0.1444\n",
            "Epoch [33/50] Step [150/313] Loss: 0.1509\n",
            "Epoch [33/50] Step [200/313] Loss: 0.1849\n",
            "Epoch [33/50] Step [250/313] Loss: 0.1586\n",
            "Epoch [33/50] Step [300/313] Loss: 0.1781\n",
            "Epoch 33 Saved.\n",
            "Epoch [34/50] Step [0/313] Loss: 0.1550\n",
            "Epoch [34/50] Step [50/313] Loss: 0.1462\n",
            "Epoch [34/50] Step [100/313] Loss: 0.1714\n",
            "Epoch [34/50] Step [150/313] Loss: 0.1670\n",
            "Epoch [34/50] Step [200/313] Loss: 0.1745\n",
            "Epoch [34/50] Step [250/313] Loss: 0.2007\n",
            "Epoch [34/50] Step [300/313] Loss: 0.1647\n",
            "Epoch 34 Saved.\n",
            "Epoch [35/50] Step [0/313] Loss: 0.1723\n",
            "Epoch [35/50] Step [50/313] Loss: 0.1793\n",
            "Epoch [35/50] Step [100/313] Loss: 0.1623\n",
            "Epoch [35/50] Step [150/313] Loss: 0.1540\n",
            "Epoch [35/50] Step [200/313] Loss: 0.1617\n",
            "Epoch [35/50] Step [250/313] Loss: 0.2007\n",
            "Epoch [35/50] Step [300/313] Loss: 0.1404\n",
            "Epoch 35 Saved.\n",
            "Epoch [36/50] Step [0/313] Loss: 0.1575\n",
            "Epoch [36/50] Step [50/313] Loss: 0.1809\n",
            "Epoch [36/50] Step [100/313] Loss: 0.1516\n",
            "Epoch [36/50] Step [150/313] Loss: 0.1624\n",
            "Epoch [36/50] Step [200/313] Loss: 0.1746\n",
            "Epoch [36/50] Step [250/313] Loss: 0.1508\n",
            "Epoch [36/50] Step [300/313] Loss: 0.1513\n",
            "Epoch 36 Saved.\n",
            "Epoch [37/50] Step [0/313] Loss: 0.1544\n",
            "Epoch [37/50] Step [50/313] Loss: 0.1772\n",
            "Epoch [37/50] Step [100/313] Loss: 0.2010\n",
            "Epoch [37/50] Step [150/313] Loss: 0.2092\n",
            "Epoch [37/50] Step [200/313] Loss: 0.2072\n",
            "Epoch [37/50] Step [250/313] Loss: 0.2014\n",
            "Epoch [37/50] Step [300/313] Loss: 0.1880\n",
            "Epoch 37 Saved.\n",
            "Epoch [38/50] Step [0/313] Loss: 0.1713\n",
            "Epoch [38/50] Step [50/313] Loss: 0.1986\n",
            "Epoch [38/50] Step [100/313] Loss: 0.1706\n",
            "Epoch [38/50] Step [150/313] Loss: 0.1615\n",
            "Epoch [38/50] Step [200/313] Loss: 0.1917\n",
            "Epoch [38/50] Step [250/313] Loss: 0.1621\n",
            "Epoch [38/50] Step [300/313] Loss: 0.1642\n",
            "Epoch 38 Saved.\n",
            "Epoch [39/50] Step [0/313] Loss: 0.1476\n",
            "Epoch [39/50] Step [50/313] Loss: 0.1871\n",
            "Epoch [39/50] Step [100/313] Loss: 0.1785\n",
            "Epoch [39/50] Step [150/313] Loss: 0.1451\n",
            "Epoch [39/50] Step [200/313] Loss: 0.1405\n",
            "Epoch [39/50] Step [250/313] Loss: 0.1607\n",
            "Epoch [39/50] Step [300/313] Loss: 0.1601\n",
            "Epoch 39 Saved.\n",
            "Epoch [40/50] Step [0/313] Loss: 0.1616\n",
            "Epoch [40/50] Step [50/313] Loss: 0.1560\n",
            "Epoch [40/50] Step [100/313] Loss: 0.1842\n",
            "Epoch [40/50] Step [150/313] Loss: 0.1946\n",
            "Epoch [40/50] Step [200/313] Loss: 0.1528\n",
            "Epoch [40/50] Step [250/313] Loss: 0.1546\n",
            "Epoch [40/50] Step [300/313] Loss: 0.1807\n",
            "Epoch 40 Saved.\n",
            "Epoch [41/50] Step [0/313] Loss: 0.1361\n",
            "Epoch [41/50] Step [50/313] Loss: 0.1291\n",
            "Epoch [41/50] Step [100/313] Loss: 0.1669\n",
            "Epoch [41/50] Step [150/313] Loss: 0.1657\n",
            "Epoch [41/50] Step [200/313] Loss: 0.1644\n",
            "Epoch [41/50] Step [250/313] Loss: 0.1735\n",
            "Epoch [41/50] Step [300/313] Loss: 0.1483\n",
            "Epoch 41 Saved.\n",
            "Epoch [42/50] Step [0/313] Loss: 0.1660\n",
            "Epoch [42/50] Step [50/313] Loss: 0.1261\n",
            "Epoch [42/50] Step [100/313] Loss: 0.1501\n",
            "Epoch [42/50] Step [150/313] Loss: 0.1609\n",
            "Epoch [42/50] Step [200/313] Loss: 0.1627\n",
            "Epoch [42/50] Step [250/313] Loss: 0.1652\n",
            "Epoch [42/50] Step [300/313] Loss: 0.1484\n",
            "Epoch 42 Saved.\n",
            "Epoch [43/50] Step [0/313] Loss: 0.1624\n",
            "Epoch [43/50] Step [50/313] Loss: 0.1436\n",
            "Epoch [43/50] Step [100/313] Loss: 0.1578\n",
            "Epoch [43/50] Step [150/313] Loss: 0.1558\n",
            "Epoch [43/50] Step [200/313] Loss: 0.1494\n",
            "Epoch [43/50] Step [250/313] Loss: 0.1836\n",
            "Epoch [43/50] Step [300/313] Loss: 0.1427\n",
            "Epoch 43 Saved.\n",
            "Epoch [44/50] Step [0/313] Loss: 0.1581\n",
            "Epoch [44/50] Step [50/313] Loss: 0.1500\n",
            "Epoch [44/50] Step [100/313] Loss: 0.1712\n",
            "Epoch [44/50] Step [150/313] Loss: 0.1350\n",
            "Epoch [44/50] Step [200/313] Loss: 0.1640\n",
            "Epoch [44/50] Step [250/313] Loss: 0.1550\n",
            "Epoch [44/50] Step [300/313] Loss: 0.1660\n",
            "Epoch 44 Saved.\n",
            "Epoch [45/50] Step [0/313] Loss: 0.1923\n",
            "Epoch [45/50] Step [50/313] Loss: 0.1685\n",
            "Epoch [45/50] Step [100/313] Loss: 0.1614\n",
            "Epoch [45/50] Step [150/313] Loss: 0.1791\n",
            "Epoch [45/50] Step [200/313] Loss: 0.1546\n",
            "Epoch [45/50] Step [250/313] Loss: 0.1323\n",
            "Epoch [45/50] Step [300/313] Loss: 0.1628\n",
            "Epoch 45 Saved.\n",
            "Epoch [46/50] Step [0/313] Loss: 0.1354\n",
            "Epoch [46/50] Step [50/313] Loss: 0.1371\n",
            "Epoch [46/50] Step [100/313] Loss: 0.1620\n",
            "Epoch [46/50] Step [150/313] Loss: 0.1559\n",
            "Epoch [46/50] Step [200/313] Loss: 0.1691\n",
            "Epoch [46/50] Step [250/313] Loss: 0.1415\n",
            "Epoch [46/50] Step [300/313] Loss: 0.1671\n",
            "Epoch 46 Saved.\n",
            "Epoch [47/50] Step [0/313] Loss: 0.1518\n",
            "Epoch [47/50] Step [50/313] Loss: 0.1484\n",
            "Epoch [47/50] Step [100/313] Loss: 0.1495\n",
            "Epoch [47/50] Step [150/313] Loss: 0.1443\n",
            "Epoch [47/50] Step [200/313] Loss: 0.1562\n",
            "Epoch [47/50] Step [250/313] Loss: 0.1721\n",
            "Epoch [47/50] Step [300/313] Loss: 0.1583\n",
            "Epoch 47 Saved.\n",
            "Epoch [48/50] Step [0/313] Loss: 0.1431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. SETUP & IMPORTS ---\n",
        "print(\"Setting up environment...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists('/content/models'):\n",
        "    print(\"Restoring Code...\")\n",
        "    !git clone https://github.com/Gabrysse/MLDL2024_project1.git temp_repo\n",
        "    shutil.copytree('temp_repo/models', '/content/models')\n",
        "    shutil.rmtree('temp_repo')\n",
        "\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "\n",
        "# --- 2. CONFIGURATION ---\n",
        "CHECKPOINT_NAME = 'bisenet_aug1_checkpoint.pth'\n",
        "TARGET_EPOCHS = 50\n",
        "FORCED_START_EPOCH = 48\n",
        "BATCH_SIZE = 8\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DATASET_DIR = '/content/dataset'\n",
        "GTA_PATH = os.path.join(DATASET_DIR, 'project_data', 'gta5')\n",
        "ZIP_PATH = '/content/drive/MyDrive/semseg/project_data.zip'\n",
        "\n",
        "# --- 3. DATASET CHECK ---\n",
        "if not os.path.exists(GTA_PATH):\n",
        "    print(\"Restoring Dataset...\")\n",
        "    if not os.path.exists(DATASET_DIR): os.makedirs(DATASET_DIR)\n",
        "    if os.path.exists(ZIP_PATH):\n",
        "        shutil.unpack_archive(ZIP_PATH, DATASET_DIR)\n",
        "        print(\"Dataset ready.\")\n",
        "    else:\n",
        "        print(f\"Error: Zip file not found at {ZIP_PATH}\")\n",
        "        sys.exit()\n",
        "\n",
        "# --- 4. DATASET CLASS ---\n",
        "class GTA5Aug1Dataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.images_dir = os.path.join(root_dir, 'images')\n",
        "        self.masks_dir = os.path.join(root_dir, 'labels')\n",
        "        self.images = sorted(os.listdir(self.images_dir))\n",
        "        self.normalize = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        self.id_mapping = {\n",
        "            7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 17: 5,\n",
        "            19: 6, 20: 7, 21: 8, 22: 9, 23: 10, 24: 11, 25: 12,\n",
        "            26: 13, 27: 14, 28: 15, 31: 16, 32: 17, 33: 18\n",
        "        }\n",
        "\n",
        "    def __len__(self): return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.images_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.masks_dir, self.images[idx])\n",
        "        image = Image.open(img_path).convert('RGB').resize((1280, 720), Image.BILINEAR)\n",
        "        mask = Image.open(mask_path).resize((1280, 720), Image.NEAREST)\n",
        "\n",
        "        # AUG 1 ONLY: Random Flip\n",
        "        if random.random() > 0.5:\n",
        "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            mask = mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "        image = self.normalize(image)\n",
        "        mask_np = np.array(mask)\n",
        "        target_mask = np.full(mask_np.shape, 255, dtype=np.uint8)\n",
        "        for k, v in self.id_mapping.items(): target_mask[mask_np == k] = v\n",
        "        return image, torch.from_numpy(target_mask).long()\n",
        "\n",
        "# --- 5. RESUME TRAINING ---\n",
        "print(f\"Resuming Training for {CHECKPOINT_NAME}...\")\n",
        "\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18').to(DEVICE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "checkpoint_path = f'/content/drive/MyDrive/{CHECKPOINT_NAME}'\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(\"Loading checkpoint weights...\")\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    if 'optimizer_state_dict' in checkpoint:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "else:\n",
        "    print(\"Warning: No checkpoint found. Starting from scratch.\")\n",
        "\n",
        "\n",
        "start_epoch = FORCED_START_EPOCH\n",
        "print(f\"Forcing start at Epoch {start_epoch}\")\n",
        "\n",
        "dataset = GTA5Aug1Dataset(GTA_PATH)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, TARGET_EPOCHS + 1):\n",
        "    model.train()\n",
        "    for i, (img, lbl) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(img.to(DEVICE))\n",
        "        loss = criterion(out[0], lbl.to(DEVICE)) + 0.1 * criterion(out[1], lbl.to(DEVICE)) + 0.1 * criterion(out[2], lbl.to(DEVICE))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Epoch [{epoch}/{TARGET_EPOCHS}] Step [{i}/{len(loader)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, checkpoint_path)\n",
        "    print(f\"Epoch {epoch} Saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTeYvPzhy_5o",
        "outputId": "ea6b16d1-1c2a-4500-c88d-d3e4a44c2ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up environment...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Resuming Training for bisenet_aug1_checkpoint.pth...\n",
            "Loading checkpoint weights...\n",
            "Forcing start at Epoch 48\n",
            "Epoch [48/50] Step [0/313] Loss: 0.1827\n",
            "Epoch [48/50] Step [50/313] Loss: 0.1520\n",
            "Epoch [48/50] Step [100/313] Loss: 0.1629\n",
            "Epoch [48/50] Step [150/313] Loss: 0.1508\n",
            "Epoch [48/50] Step [200/313] Loss: 0.1911\n",
            "Epoch [48/50] Step [250/313] Loss: 0.2324\n",
            "Epoch [48/50] Step [300/313] Loss: 0.2210\n",
            "Epoch 48 Saved.\n",
            "Epoch [49/50] Step [0/313] Loss: 0.2024\n",
            "Epoch [49/50] Step [50/313] Loss: 0.2114\n",
            "Epoch [49/50] Step [100/313] Loss: 0.2160\n",
            "Epoch [49/50] Step [150/313] Loss: 0.1825\n",
            "Epoch [49/50] Step [200/313] Loss: 0.2142\n",
            "Epoch [49/50] Step [250/313] Loss: 0.1771\n",
            "Epoch [49/50] Step [300/313] Loss: 0.1652\n",
            "Epoch 49 Saved.\n",
            "Epoch [50/50] Step [0/313] Loss: 0.1624\n",
            "Epoch [50/50] Step [50/313] Loss: 0.1752\n",
            "Epoch [50/50] Step [100/313] Loss: 0.1590\n",
            "Epoch [50/50] Step [150/313] Loss: 0.1703\n",
            "Epoch [50/50] Step [200/313] Loss: 0.1566\n",
            "Epoch [50/50] Step [250/313] Loss: 0.1531\n",
            "Epoch [50/50] Step [300/313] Loss: 0.1869\n",
            "Epoch 50 Saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "CITYSCAPES_PATH = '/content/dataset/project_data/cityscapes'\n",
        "CHECKPOINT_PATH = '/content/drive/MyDrive/bisenet_aug1_checkpoint.pth'\n",
        "NUM_CLASSES = 19\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "CLASSES = [\n",
        "    \"Road\", \"Sidewalk\", \"Building\", \"Wall\", \"Fence\", \"Pole\",\n",
        "    \"Traffic Light\", \"Traffic Sign\", \"Vegetation\", \"Terrain\", \"Sky\",\n",
        "    \"Person\", \"Rider\", \"Car\", \"Truck\", \"Bus\", \"Train\", \"Motorcycle\", \"Bicycle\"\n",
        "]\n",
        "\n",
        "if os.path.exists('/content/models'): sys.path.append('/content/models')\n",
        "\n",
        "class CityscapesDataset(Dataset):\n",
        "    def __init__(self, root, split='val', transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.images_dir = os.path.join(root, 'leftImg8bit', split)\n",
        "        self.masks_dir = os.path.join(root, 'gtFine', split)\n",
        "        self.images = []\n",
        "        self.masks = []\n",
        "        if os.path.exists(self.images_dir):\n",
        "            for city in sorted(os.listdir(self.images_dir)):\n",
        "                img_dir_path = os.path.join(self.images_dir, city)\n",
        "                mask_dir_path = os.path.join(self.masks_dir, city)\n",
        "                if not os.path.isdir(img_dir_path): continue\n",
        "                for file_name in sorted(os.listdir(img_dir_path)):\n",
        "                    if file_name.endswith('_leftImg8bit.png'):\n",
        "                        self.images.append(os.path.join(img_dir_path, file_name))\n",
        "                        mask_name = file_name.replace('_leftImg8bit.png', '_gtFine_labelTrainIds.png')\n",
        "                        self.masks.append(os.path.join(mask_dir_path, mask_name))\n",
        "\n",
        "    def __len__(self): return len(self.images)\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx]).convert('RGB').resize((1024, 512), Image.BILINEAR)\n",
        "        mask = Image.open(self.masks[idx]).resize((1024, 512), Image.NEAREST)\n",
        "        if self.transform: image = self.transform(image)\n",
        "        return image, torch.from_numpy(np.array(mask)).long()\n",
        "\n",
        "print(f\"Evaluating: {CHECKPOINT_PATH}\")\n",
        "model = BiSeNet(num_classes=NUM_CLASSES, context_path='resnet18')\n",
        "model.to(DEVICE)\n",
        "\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(\"Model loaded.\")\n",
        "else:\n",
        "    print(\"Checkpoint not found.\")\n",
        "    sys.exit()\n",
        "\n",
        "model.eval()\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "dataset = CityscapesDataset(CITYSCAPES_PATH, split='val', transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "hist = np.zeros((NUM_CLASSES, NUM_CLASSES))\n",
        "print(\"Processing...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(dataloader):\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.numpy()\n",
        "        output = model(images)\n",
        "        if isinstance(output, tuple): output = output[0]\n",
        "        preds = torch.argmax(output, dim=1).cpu().numpy()\n",
        "        mask = (labels >= 0) & (labels < NUM_CLASSES)\n",
        "        hist += np.bincount(\n",
        "            NUM_CLASSES * labels[mask].astype(int) + preds[mask],\n",
        "            minlength=NUM_CLASSES ** 2\n",
        "        ).reshape(NUM_CLASSES, NUM_CLASSES)\n",
        "\n",
        "iou = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
        "miou = np.nanmean(iou)\n",
        "\n",
        "print(f\"\\nFinal mIoU: {miou * 100:.2f}%\")\n",
        "print(\"-\" * 30)\n",
        "for i, class_name in enumerate(CLASSES):\n",
        "    print(f\"{class_name:15s}: {iou[i] * 100:.2f}%\")\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MiKdPad3gBY",
        "outputId": "4352d1fb-ea6a-4ccf-d7df-ad4d0e7d23e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating: /content/drive/MyDrive/bisenet_aug1_checkpoint.pth\n",
            "Model loaded.\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:58<00:00,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final mIoU: 16.45%\n",
            "------------------------------\n",
            "Road           : 8.39%\n",
            "Sidewalk       : 10.40%\n",
            "Building       : 55.77%\n",
            "Wall           : 13.54%\n",
            "Fence          : 8.44%\n",
            "Pole           : 4.36%\n",
            "Traffic Light  : 5.91%\n",
            "Traffic Sign   : 3.92%\n",
            "Vegetation     : 70.44%\n",
            "Terrain        : 5.92%\n",
            "Sky            : 66.95%\n",
            "Person         : 32.06%\n",
            "Rider          : 0.00%\n",
            "Car            : 22.15%\n",
            "Truck          : 1.44%\n",
            "Bus            : 2.90%\n",
            "Train          : 0.00%\n",
            "Motorcycle     : 0.00%\n",
            "Bicycle        : 0.00%\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}