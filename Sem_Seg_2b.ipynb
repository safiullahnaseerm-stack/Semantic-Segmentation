{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrLeKm75weIw",
        "outputId": "f3252b59-aa70-4a74-f147-b4e2710dab83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Restoring Cityscapes...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Restore Dataset\n",
        "if not os.path.exists('/content/dataset/project_data/cityscapes'):\n",
        "    print(\"Restoring Cityscapes...\")\n",
        "    zip_path_1 = '/content/drive/MyDrive/semseg/project_data.zip'\n",
        "    zip_path_2 = '/content/drive/MyDrive/project_data.zip'\n",
        "\n",
        "    if os.path.exists(zip_path_1):\n",
        "        shutil.unpack_archive(zip_path_1, '/content/dataset')\n",
        "    elif os.path.exists(zip_path_2):\n",
        "        shutil.unpack_archive(zip_path_2, '/content/dataset')\n",
        "    else:\n",
        "        print(\"Dataset zip not found. Please check paths.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# --- 1. SETUP & IMPORTS ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ðŸš€ Training on device: {device}\")\n",
        "\n",
        "# Import the model from the specific file we found earlier\n",
        "try:\n",
        "    from models.bisenet.build_bisenet import BiSeNet\n",
        "except ImportError:\n",
        "    # Safety fallback if python path is different\n",
        "    sys.path.append('/content/MLDL2024_project1')\n",
        "    from models.bisenet.build_bisenet import BiSeNet\n",
        "\n",
        "# --- 2. INITIALIZE MODEL ---\n",
        "# We use 'context_path' because that is what your build_bisenet.py requires\n",
        "print(\"Initializing BiSeNet with ResNet18...\")\n",
        "try:\n",
        "    model = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "except TypeError:\n",
        "    # Fallback if the argument name is different in some versions\n",
        "    model = BiSeNet(n_classes=19, backbone='resnet18')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# --- 3. OPTIMIZER & LOSS ---\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255) # 255 is the 'void' class to ignore\n",
        "\n",
        "# --- 4. CHECKPOINT SYSTEM (Saves to Google Drive) ---\n",
        "checkpoint_path = '/content/drive/MyDrive/bisenet_cityscapes_checkpoint.pth'\n",
        "start_epoch = 0\n",
        "num_epochs = 50\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"ðŸ”„ Found checkpoint at {checkpoint_path}. Resuming...\")\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"Resuming from Epoch {start_epoch}\")\n",
        "else:\n",
        "    print(\"ðŸ†• Starting fresh training...\")\n",
        "\n",
        "# --- 5. TRAINING LOOP ---\n",
        "print(f\"Starting training for {num_epochs} epochs...\")\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # train_loader must be defined from the previous step\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass (BiSeNet outputs a tuple: main_loss, aux1, aux2)\n",
        "        outputs = model(images)\n",
        "\n",
        "        if isinstance(outputs, tuple):\n",
        "            # Calculate loss for all 3 outputs for better training stability\n",
        "            loss_main = criterion(outputs[0], labels)\n",
        "            loss_aux1 = criterion(outputs[1], labels)\n",
        "            loss_aux2 = criterion(outputs[2], labels)\n",
        "            loss = loss_main + 0.1 * loss_aux1 + 0.1 * loss_aux2\n",
        "        else:\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Print status every 50 batches\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] Step [{i}/{len(train_loader)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # SAVE CHECKPOINT\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': running_loss\n",
        "    }, checkpoint_path)\n",
        "\n",
        "    print(f\"âœ… Epoch {epoch+1} Complete. Checkpoint saved.\")\n",
        "\n",
        "print(\"ðŸŽ‰ Training Finished!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSOW4k6UvXI-",
        "outputId": "ac6a936b-1b11-4d80-caa6-e35c6165fc97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Training on device: cuda\n",
            "Initializing BiSeNet with ResNet18...\n",
            "ðŸ†• Starting fresh training...\n",
            "Starting training for 50 epochs...\n",
            "Epoch [1/50] Step [0/197] Loss: 4.8958\n",
            "Epoch [1/50] Step [50/197] Loss: 0.9754\n",
            "Epoch [1/50] Step [100/197] Loss: 0.8764\n",
            "Epoch [1/50] Step [150/197] Loss: 0.7089\n",
            "âœ… Epoch 1 Complete. Checkpoint saved.\n",
            "Epoch [2/50] Step [0/197] Loss: 0.6278\n",
            "Epoch [2/50] Step [50/197] Loss: 0.5402\n",
            "Epoch [2/50] Step [100/197] Loss: 0.5668\n",
            "Epoch [2/50] Step [150/197] Loss: 0.6074\n",
            "âœ… Epoch 2 Complete. Checkpoint saved.\n",
            "Epoch [3/50] Step [0/197] Loss: 0.4910\n",
            "Epoch [3/50] Step [50/197] Loss: 0.6091\n",
            "Epoch [3/50] Step [100/197] Loss: 0.5502\n",
            "Epoch [3/50] Step [150/197] Loss: 0.4078\n",
            "âœ… Epoch 3 Complete. Checkpoint saved.\n",
            "Epoch [4/50] Step [0/197] Loss: 0.3835\n",
            "Epoch [4/50] Step [50/197] Loss: 0.4872\n",
            "Epoch [4/50] Step [100/197] Loss: 0.4115\n",
            "Epoch [4/50] Step [150/197] Loss: 0.4065\n",
            "âœ… Epoch 4 Complete. Checkpoint saved.\n",
            "Epoch [5/50] Step [0/197] Loss: 0.3774\n",
            "Epoch [5/50] Step [50/197] Loss: 0.3590\n",
            "Epoch [5/50] Step [100/197] Loss: 0.3357\n",
            "Epoch [5/50] Step [150/197] Loss: 0.3172\n",
            "âœ… Epoch 5 Complete. Checkpoint saved.\n",
            "Epoch [6/50] Step [0/197] Loss: 0.2820\n",
            "Epoch [6/50] Step [50/197] Loss: 0.2723\n",
            "Epoch [6/50] Step [100/197] Loss: 0.3502\n",
            "Epoch [6/50] Step [150/197] Loss: 0.3645\n",
            "âœ… Epoch 6 Complete. Checkpoint saved.\n",
            "Epoch [7/50] Step [0/197] Loss: 0.2974\n",
            "Epoch [7/50] Step [50/197] Loss: 0.2971\n",
            "Epoch [7/50] Step [100/197] Loss: 0.2471\n",
            "Epoch [7/50] Step [150/197] Loss: 0.2979\n",
            "âœ… Epoch 7 Complete. Checkpoint saved.\n",
            "Epoch [8/50] Step [0/197] Loss: 0.2522\n",
            "Epoch [8/50] Step [50/197] Loss: 0.2676\n",
            "Epoch [8/50] Step [100/197] Loss: 0.2644\n",
            "Epoch [8/50] Step [150/197] Loss: 0.2558\n",
            "âœ… Epoch 8 Complete. Checkpoint saved.\n",
            "Epoch [9/50] Step [0/197] Loss: 0.2464\n",
            "Epoch [9/50] Step [50/197] Loss: 0.2373\n",
            "Epoch [9/50] Step [100/197] Loss: 0.2396\n",
            "Epoch [9/50] Step [150/197] Loss: 0.2209\n",
            "âœ… Epoch 9 Complete. Checkpoint saved.\n",
            "Epoch [10/50] Step [0/197] Loss: 0.2689\n",
            "Epoch [10/50] Step [50/197] Loss: 0.3097\n",
            "Epoch [10/50] Step [100/197] Loss: 0.2527\n",
            "Epoch [10/50] Step [150/197] Loss: 0.2469\n",
            "âœ… Epoch 10 Complete. Checkpoint saved.\n",
            "Epoch [11/50] Step [0/197] Loss: 0.2565\n",
            "Epoch [11/50] Step [50/197] Loss: 0.2917\n",
            "Epoch [11/50] Step [100/197] Loss: 0.2365\n",
            "Epoch [11/50] Step [150/197] Loss: 0.2547\n",
            "âœ… Epoch 11 Complete. Checkpoint saved.\n",
            "Epoch [12/50] Step [0/197] Loss: 0.2102\n",
            "Epoch [12/50] Step [50/197] Loss: 0.2269\n",
            "Epoch [12/50] Step [100/197] Loss: 0.2822\n",
            "Epoch [12/50] Step [150/197] Loss: 0.2474\n",
            "âœ… Epoch 12 Complete. Checkpoint saved.\n",
            "Epoch [13/50] Step [0/197] Loss: 0.2670\n",
            "Epoch [13/50] Step [50/197] Loss: 0.1951\n",
            "Epoch [13/50] Step [100/197] Loss: 0.2207\n",
            "Epoch [13/50] Step [150/197] Loss: 0.2345\n",
            "âœ… Epoch 13 Complete. Checkpoint saved.\n",
            "Epoch [14/50] Step [0/197] Loss: 0.2093\n",
            "Epoch [14/50] Step [50/197] Loss: 0.2793\n",
            "Epoch [14/50] Step [100/197] Loss: 0.2021\n",
            "Epoch [14/50] Step [150/197] Loss: 0.2253\n",
            "âœ… Epoch 14 Complete. Checkpoint saved.\n",
            "Epoch [15/50] Step [0/197] Loss: 0.2145\n",
            "Epoch [15/50] Step [50/197] Loss: 0.2513\n",
            "Epoch [15/50] Step [100/197] Loss: 0.2379\n",
            "Epoch [15/50] Step [150/197] Loss: 0.2491\n",
            "âœ… Epoch 15 Complete. Checkpoint saved.\n",
            "Epoch [16/50] Step [0/197] Loss: 0.2146\n",
            "Epoch [16/50] Step [50/197] Loss: 0.2421\n",
            "Epoch [16/50] Step [100/197] Loss: 0.1753\n",
            "Epoch [16/50] Step [150/197] Loss: 0.2231\n",
            "âœ… Epoch 16 Complete. Checkpoint saved.\n",
            "Epoch [17/50] Step [0/197] Loss: 0.1860\n",
            "Epoch [17/50] Step [50/197] Loss: 0.1996\n",
            "Epoch [17/50] Step [100/197] Loss: 0.2255\n",
            "Epoch [17/50] Step [150/197] Loss: 0.1915\n",
            "âœ… Epoch 17 Complete. Checkpoint saved.\n",
            "Epoch [18/50] Step [0/197] Loss: 0.2099\n",
            "Epoch [18/50] Step [50/197] Loss: 0.2265\n",
            "Epoch [18/50] Step [100/197] Loss: 0.2216\n",
            "Epoch [18/50] Step [150/197] Loss: 0.1817\n",
            "âœ… Epoch 18 Complete. Checkpoint saved.\n",
            "Epoch [19/50] Step [0/197] Loss: 0.1999\n",
            "Epoch [19/50] Step [50/197] Loss: 0.2068\n",
            "Epoch [19/50] Step [100/197] Loss: 0.2326\n",
            "Epoch [19/50] Step [150/197] Loss: 0.1934\n",
            "âœ… Epoch 19 Complete. Checkpoint saved.\n",
            "Epoch [20/50] Step [0/197] Loss: 0.1756\n",
            "Epoch [20/50] Step [50/197] Loss: 0.1938\n",
            "Epoch [20/50] Step [100/197] Loss: 0.1717\n",
            "Epoch [20/50] Step [150/197] Loss: 0.2035\n",
            "âœ… Epoch 20 Complete. Checkpoint saved.\n",
            "Epoch [21/50] Step [0/197] Loss: 0.2125\n",
            "Epoch [21/50] Step [50/197] Loss: 0.1725\n",
            "Epoch [21/50] Step [100/197] Loss: 0.1906\n",
            "Epoch [21/50] Step [150/197] Loss: 0.1836\n",
            "âœ… Epoch 21 Complete. Checkpoint saved.\n",
            "Epoch [22/50] Step [0/197] Loss: 0.1972\n",
            "Epoch [22/50] Step [50/197] Loss: 0.1823\n",
            "Epoch [22/50] Step [100/197] Loss: 0.2159\n",
            "Epoch [22/50] Step [150/197] Loss: 0.2344\n",
            "âœ… Epoch 22 Complete. Checkpoint saved.\n",
            "Epoch [23/50] Step [0/197] Loss: 0.2032\n",
            "Epoch [23/50] Step [50/197] Loss: 0.1909\n",
            "Epoch [23/50] Step [100/197] Loss: 0.2202\n",
            "Epoch [23/50] Step [150/197] Loss: 0.1381\n",
            "âœ… Epoch 23 Complete. Checkpoint saved.\n",
            "Epoch [24/50] Step [0/197] Loss: 0.1515\n",
            "Epoch [24/50] Step [50/197] Loss: 0.2142\n",
            "Epoch [24/50] Step [100/197] Loss: 0.1863\n",
            "Epoch [24/50] Step [150/197] Loss: 0.2382\n",
            "âœ… Epoch 24 Complete. Checkpoint saved.\n",
            "Epoch [25/50] Step [0/197] Loss: 0.1498\n",
            "Epoch [25/50] Step [50/197] Loss: 0.2186\n",
            "Epoch [25/50] Step [100/197] Loss: 0.2127\n",
            "Epoch [25/50] Step [150/197] Loss: 0.2317\n",
            "âœ… Epoch 25 Complete. Checkpoint saved.\n",
            "Epoch [26/50] Step [0/197] Loss: 0.1474\n",
            "Epoch [26/50] Step [50/197] Loss: 0.1657\n",
            "Epoch [26/50] Step [100/197] Loss: 0.1474\n",
            "Epoch [26/50] Step [150/197] Loss: 0.1876\n",
            "âœ… Epoch 26 Complete. Checkpoint saved.\n",
            "Epoch [27/50] Step [0/197] Loss: 0.1645\n",
            "Epoch [27/50] Step [50/197] Loss: 0.1738\n",
            "Epoch [27/50] Step [100/197] Loss: 0.1961\n",
            "Epoch [27/50] Step [150/197] Loss: 0.1600\n",
            "âœ… Epoch 27 Complete. Checkpoint saved.\n",
            "Epoch [28/50] Step [0/197] Loss: 0.1870\n",
            "Epoch [28/50] Step [50/197] Loss: 0.1451\n",
            "Epoch [28/50] Step [100/197] Loss: 0.1502\n",
            "Epoch [28/50] Step [150/197] Loss: 0.2085\n",
            "âœ… Epoch 28 Complete. Checkpoint saved.\n",
            "Epoch [29/50] Step [0/197] Loss: 0.1914\n",
            "Epoch [29/50] Step [50/197] Loss: 0.1441\n",
            "Epoch [29/50] Step [100/197] Loss: 0.2080\n",
            "Epoch [29/50] Step [150/197] Loss: 0.2031\n",
            "âœ… Epoch 29 Complete. Checkpoint saved.\n",
            "Epoch [30/50] Step [0/197] Loss: 0.1433\n",
            "Epoch [30/50] Step [50/197] Loss: 0.1874\n",
            "Epoch [30/50] Step [100/197] Loss: 0.1478\n",
            "Epoch [30/50] Step [150/197] Loss: 0.1705\n",
            "âœ… Epoch 30 Complete. Checkpoint saved.\n",
            "Epoch [31/50] Step [0/197] Loss: 0.1798\n",
            "Epoch [31/50] Step [50/197] Loss: 0.1546\n",
            "Epoch [31/50] Step [100/197] Loss: 0.1616\n",
            "Epoch [31/50] Step [150/197] Loss: 0.1696\n",
            "âœ… Epoch 31 Complete. Checkpoint saved.\n",
            "Epoch [32/50] Step [0/197] Loss: 0.1736\n",
            "Epoch [32/50] Step [50/197] Loss: 0.1610\n",
            "Epoch [32/50] Step [100/197] Loss: 0.2003\n",
            "Epoch [32/50] Step [150/197] Loss: 0.1553\n",
            "âœ… Epoch 32 Complete. Checkpoint saved.\n",
            "Epoch [33/50] Step [0/197] Loss: 0.1590\n",
            "Epoch [33/50] Step [50/197] Loss: 0.1566\n",
            "Epoch [33/50] Step [100/197] Loss: 0.1591\n",
            "Epoch [33/50] Step [150/197] Loss: 0.1475\n",
            "âœ… Epoch 33 Complete. Checkpoint saved.\n",
            "Epoch [34/50] Step [0/197] Loss: 0.1643\n",
            "Epoch [34/50] Step [50/197] Loss: 0.1448\n",
            "Epoch [34/50] Step [100/197] Loss: 0.1681\n",
            "Epoch [34/50] Step [150/197] Loss: 0.2210\n",
            "âœ… Epoch 34 Complete. Checkpoint saved.\n",
            "Epoch [35/50] Step [0/197] Loss: 0.1776\n",
            "Epoch [35/50] Step [50/197] Loss: 0.1385\n",
            "Epoch [35/50] Step [100/197] Loss: 0.1544\n",
            "Epoch [35/50] Step [150/197] Loss: 0.2197\n",
            "âœ… Epoch 35 Complete. Checkpoint saved.\n",
            "Epoch [36/50] Step [0/197] Loss: 0.1668\n",
            "Epoch [36/50] Step [50/197] Loss: 0.1642\n",
            "Epoch [36/50] Step [100/197] Loss: 0.1636\n",
            "Epoch [36/50] Step [150/197] Loss: 0.1366\n",
            "âœ… Epoch 36 Complete. Checkpoint saved.\n",
            "Epoch [37/50] Step [0/197] Loss: 0.1960\n",
            "Epoch [37/50] Step [50/197] Loss: 0.1445\n",
            "Epoch [37/50] Step [100/197] Loss: 0.1383\n",
            "Epoch [37/50] Step [150/197] Loss: 0.1488\n",
            "âœ… Epoch 37 Complete. Checkpoint saved.\n",
            "Epoch [38/50] Step [0/197] Loss: 0.1891\n",
            "Epoch [38/50] Step [50/197] Loss: 0.1731\n",
            "Epoch [38/50] Step [100/197] Loss: 0.1712\n",
            "Epoch [38/50] Step [150/197] Loss: 0.1725\n",
            "âœ… Epoch 38 Complete. Checkpoint saved.\n",
            "Epoch [39/50] Step [0/197] Loss: 0.1697\n",
            "Epoch [39/50] Step [50/197] Loss: 0.1731\n",
            "Epoch [39/50] Step [100/197] Loss: 0.1438\n",
            "Epoch [39/50] Step [150/197] Loss: 0.1470\n",
            "âœ… Epoch 39 Complete. Checkpoint saved.\n",
            "Epoch [40/50] Step [0/197] Loss: 0.1707\n",
            "Epoch [40/50] Step [50/197] Loss: 0.1712\n",
            "Epoch [40/50] Step [100/197] Loss: 0.1420\n",
            "Epoch [40/50] Step [150/197] Loss: 0.1905\n",
            "âœ… Epoch 40 Complete. Checkpoint saved.\n",
            "Epoch [41/50] Step [0/197] Loss: 0.1356\n",
            "Epoch [41/50] Step [50/197] Loss: 0.1743\n",
            "Epoch [41/50] Step [100/197] Loss: 0.1514\n",
            "Epoch [41/50] Step [150/197] Loss: 0.1659\n",
            "âœ… Epoch 41 Complete. Checkpoint saved.\n",
            "Epoch [42/50] Step [0/197] Loss: 0.1266\n",
            "Epoch [42/50] Step [50/197] Loss: 0.1389\n",
            "Epoch [42/50] Step [100/197] Loss: 0.1569\n",
            "Epoch [42/50] Step [150/197] Loss: 0.1531\n",
            "âœ… Epoch 42 Complete. Checkpoint saved.\n",
            "Epoch [43/50] Step [0/197] Loss: 0.1752\n",
            "Epoch [43/50] Step [50/197] Loss: 0.1450\n",
            "Epoch [43/50] Step [100/197] Loss: 0.1877\n",
            "Epoch [43/50] Step [150/197] Loss: 0.1338\n",
            "âœ… Epoch 43 Complete. Checkpoint saved.\n",
            "Epoch [44/50] Step [0/197] Loss: 0.1363\n",
            "Epoch [44/50] Step [50/197] Loss: 0.1601\n",
            "Epoch [44/50] Step [100/197] Loss: 0.1726\n",
            "Epoch [44/50] Step [150/197] Loss: 0.1513\n",
            "âœ… Epoch 44 Complete. Checkpoint saved.\n",
            "Epoch [45/50] Step [0/197] Loss: 0.1710\n",
            "Epoch [45/50] Step [50/197] Loss: 0.1238\n",
            "Epoch [45/50] Step [100/197] Loss: 0.1252\n",
            "Epoch [45/50] Step [150/197] Loss: 0.1505\n",
            "âœ… Epoch 45 Complete. Checkpoint saved.\n",
            "Epoch [46/50] Step [0/197] Loss: 0.1365\n",
            "Epoch [46/50] Step [50/197] Loss: 0.1251\n",
            "Epoch [46/50] Step [100/197] Loss: 0.1682\n",
            "Epoch [46/50] Step [150/197] Loss: 0.1390\n",
            "âœ… Epoch 46 Complete. Checkpoint saved.\n",
            "Epoch [47/50] Step [0/197] Loss: 0.1460\n",
            "Epoch [47/50] Step [50/197] Loss: 0.1138\n",
            "Epoch [47/50] Step [100/197] Loss: 0.1840\n",
            "Epoch [47/50] Step [150/197] Loss: 0.1353\n",
            "âœ… Epoch 47 Complete. Checkpoint saved.\n",
            "Epoch [48/50] Step [0/197] Loss: 0.1443\n",
            "Epoch [48/50] Step [50/197] Loss: 0.1470\n",
            "Epoch [48/50] Step [100/197] Loss: 0.1770\n",
            "Epoch [48/50] Step [150/197] Loss: 0.1414\n",
            "âœ… Epoch 48 Complete. Checkpoint saved.\n",
            "Epoch [49/50] Step [0/197] Loss: 0.1484\n",
            "Epoch [49/50] Step [50/197] Loss: 0.1437\n",
            "Epoch [49/50] Step [100/197] Loss: 0.1414\n",
            "Epoch [49/50] Step [150/197] Loss: 0.1288\n",
            "âœ… Epoch 49 Complete. Checkpoint saved.\n",
            "Epoch [50/50] Step [0/197] Loss: 0.1446\n",
            "Epoch [50/50] Step [50/197] Loss: 0.1531\n",
            "Epoch [50/50] Step [100/197] Loss: 0.1602\n",
            "Epoch [50/50] Step [150/197] Loss: 0.1477\n",
            "âœ… Epoch 50 Complete. Checkpoint saved.\n",
            "ðŸŽ‰ Training Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "# Re-import to ensure we can rebuild the model\n",
        "import sys\n",
        "try:\n",
        "    from models.bisenet.build_bisenet import BiSeNet\n",
        "except ImportError:\n",
        "    sys.path.append('/content/MLDL2024_project1')\n",
        "    from models.bisenet.build_bisenet import BiSeNet\n",
        "\n",
        "# --- 1. HARD RESET: RELOAD MODEL FROM CHECKPOINT ---\n",
        "# This wipes out the \"AttributeError\" caused by thop\n",
        "print(\"ðŸ”„ Reloading model from checkpoint to clear errors...\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BiSeNet(num_classes=19, context_path='resnet18')\n",
        "model.to(device)\n",
        "\n",
        "# Load the weights you just trained\n",
        "checkpoint_path = '/content/drive/MyDrive/bisenet_cityscapes_checkpoint.pth'\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "print(\"âœ… Model restored successfully!\")\n",
        "\n",
        "# --- 2. CALCULATE mIoU (Accuracy) ---\n",
        "print(\"1ï¸âƒ£  Evaluating Accuracy (mIoU)...\")\n",
        "def fast_hist(a, b, n):\n",
        "    k = (a >= 0) & (a < n)\n",
        "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n**2).reshape(n, n)\n",
        "\n",
        "def per_class_iu(hist):\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
        "\n",
        "n_classes = 19\n",
        "hist = np.zeros((n_classes, n_classes))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (images, labels) in enumerate(val_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.numpy()\n",
        "\n",
        "        outputs = model(images)\n",
        "        if isinstance(outputs, tuple): outputs = outputs[0]\n",
        "\n",
        "        outputs = F.interpolate(outputs, size=(512, 1024), mode='bilinear', align_corners=True)\n",
        "        preds = outputs.data.max(1)[1].cpu().numpy()\n",
        "\n",
        "        hist += fast_hist(labels.flatten(), preds.flatten(), n_classes)\n",
        "\n",
        "ious = per_class_iu(hist)\n",
        "mIoU = np.nanmean(ious) * 100\n",
        "print(f\"ðŸ† mIoU Result: {mIoU:.2f}%\")\n",
        "\n",
        "# --- 3. CALCULATE LATENCY & FLOPs (Safe Mode) ---\n",
        "print(\"2ï¸âƒ£  Calculating Technical Metrics...\")\n",
        "from thop import profile, clever_format\n",
        "\n",
        "# Prepare input\n",
        "input_tensor = torch.randn(1, 3, 512, 1024).to(device)\n",
        "\n",
        "# Measure Latency FIRST\n",
        "start = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(50): _ = model(input_tensor)\n",
        "end = time.time()\n",
        "latency_ms = ((end - start) / 50) * 1000\n",
        "fps = 1000 / latency_ms\n",
        "\n",
        "# Measure FLOPs LAST (This modifies the model, so we do it at the very end)\n",
        "flops_count, params_count = profile(model, inputs=(input_tensor, ), verbose=False)\n",
        "flops_str, params_str = clever_format([flops_count, params_count], \"%.3f\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"ðŸ“Š FINAL RESULTS FOR TABLE 2\")\n",
        "print(\"=\"*40)\n",
        "print(f\"âœ… mIoU:       {mIoU:.2f}%\")\n",
        "print(f\"âœ… Latency:    {latency_ms:.2f} ms\")\n",
        "print(f\"âœ… FPS:        {fps:.2f}\")\n",
        "print(f\"âœ… FLOPs:      {flops_str}\")\n",
        "print(f\"âœ… Params:     {params_str}\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxkiScAxViqv",
        "outputId": "fa26b039-b644-4142-a729-97e6ac27aa97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Reloading model from checkpoint to clear errors...\n",
            "âœ… Model restored successfully!\n",
            "1ï¸âƒ£  Evaluating Accuracy (mIoU)...\n",
            "ðŸ† mIoU Result: 54.08%\n",
            "2ï¸âƒ£  Calculating Technical Metrics...\n",
            "\n",
            "========================================\n",
            "ðŸ“Š FINAL RESULTS FOR TABLE 2\n",
            "========================================\n",
            "âœ… mIoU:       54.08%\n",
            "âœ… Latency:    13.38 ms\n",
            "âœ… FPS:        74.76\n",
            "âœ… FLOPs:      82.957G\n",
            "âœ… Params:     23.231M\n",
            "========================================\n"
          ]
        }
      ]
    }
  ]
}